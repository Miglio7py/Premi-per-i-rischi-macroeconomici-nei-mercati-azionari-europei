{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588e5fd7-2fd2-42c0-bcf5-638046fe44df",
   "metadata": {},
   "source": [
    "# Fama e French Five Factor Model\n",
    "In questo codice vengono costruiti i 5 fattori di Fama e French, i portafogli LHS, e vengono effettuate le regressioni dei portafogli sui fattori. Per l'ottenimento degli alpha di tutti i portafogli LHS delle Germania, Francia, Italia, Spagna, Finlandia e Olanda si lancia questo codice una volta per ogni nazione con i dataset di rendimenti e caratteristiche del singolo mercato nazionale.\n",
    "Infine si salvano gli alpha trimestrali dei portafogli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6855b-263f-43e1-9af6-d21bf2f57a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e0eec-d67a-4dfb-8497-4a38aa6ba87a",
   "metadata": {},
   "source": [
    "## Import dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f06340-a810-4154-ad06-f4975fd24136",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics_dfs = [] #Lista contenente le caratteristiche delle stock\n",
    "returns_dfs = [] #Lista contenente i rendimenti delle stock\n",
    "Rf_dfs = [] #Lista contenente il tasso Euribor\n",
    "Rm_dfs = [] #Lista contenente il rendimento dell'EUROSTOCK 600\n",
    "\n",
    "#Per ogni anno vengono caricati i dataframe e aggiunti alle liste.\n",
    "for i in range(1, 21):\n",
    "    characteristics_file = f'Caratteristiche_{i}.csv'\n",
    "    returns_file = f'Rendimenti portafoglio_{i}.csv'\n",
    "    Rf_file = f'Euribor_{i}.csv'\n",
    "    Rm_file = f'EUSTOXX600_{i}.csv'\n",
    "\n",
    "    #Si assegna a tutti i df lo stesso indice\n",
    "    characteristics_df = pd.read_csv(characteristics_file, sep=';')\n",
    "    returns_df = pd.read_csv(returns_file, sep=';').set_index('Data')\n",
    "    Rf_df = pd.read_csv(Rf_file, sep=';').set_index('Data')\n",
    "    Rm_df = pd.read_csv(Rm_file, sep=';').set_index('Data')\n",
    "\n",
    "    characteristics_dfs.append(characteristics_df)\n",
    "    returns_dfs.append(returns_df)\n",
    "    Rf_dfs.append(Rf_df)\n",
    "    Rm_dfs.append(Rm_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9a071-3143-4c89-b44e-f09072fe7101",
   "metadata": {},
   "source": [
    "### Pulizia Dataframe\n",
    "Questa cella controlla che i dataframe annuali di returns_dfs e characteristics_dfs abbiano all'interno i dati relativi agli stessi titoli.\n",
    "Ogni coppia corrispondente di DataFrame per anno subisce lo stesso processo:\n",
    "\n",
    "1. Rimozione delle colonne contenenti NaN (.\n",
    "2. Identificazione delle colonne comuni.\n",
    "3. Selezione delle colonne comuni in entrambi i DataFrame.\n",
    "4. Inserimento della colonna Unnamed: 0 nel DataFrame characteristics_final.\n",
    "\n",
    "I DataFrame puliti e processati per ogni anno vengono poi memorizzati rispettivamente in returns_final_dfs e characteristics_final_dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1e47f-d646-4736-a74c-22768cd85e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_final_dfs = []\n",
    "characteristics_final_dfs = []\n",
    "\n",
    "for i in range(len(returns_dfs)):\n",
    "    # 1)\n",
    "    returns_dropped = returns_dfs[i].dropna(axis=1, how='any')\n",
    "    characteristics_dropped = characteristics_dfs[i].dropna(axis=1, how='any')\n",
    "    \n",
    "    # 2)\n",
    "    common_columns = returns_dropped.columns.intersection(characteristics_dropped.columns)\n",
    "    \n",
    "    # 3)\n",
    "    returns_final = returns_dropped[common_columns]\n",
    "    characteristics_final = characteristics_dropped[common_columns]\n",
    "    \n",
    "    # 4)\n",
    "    characteristics_final.insert(0, 'Unnamed: 0', characteristics_dfs[i]['Unnamed: 0'])\n",
    "    \n",
    "    returns_final_dfs.append(returns_final)\n",
    "    characteristics_final_dfs.append(characteristics_final)\n",
    "    \n",
    "    print(f\"Dimensione di 'returns' per anno {i+1} dopo il drop e mantenimento colonne comuni: {returns_final.shape}\")\n",
    "    print(f\"Dimensione di 'characteristics' per anno {i+1} dopo il drop e mantenimento colonne comuni: {characteristics_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc609e1-f9ab-459e-b3d0-863155bf1514",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Costruzione Fattori\n",
    "In questa sezione si costruiscono i 5 fattori di Fama e French giornalieri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9d564-b2fc-4a9b-95bd-ce8554e8076d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Suddivisione per ogni anno delle stock per categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9490b3-2d15-44be-947b-bae4d20e3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_portafogli_SMB_1 = []\n",
    "all_portafogli_SMB_2 = []\n",
    "all_portafogli_SMB_3 = []\n",
    "all_portafogli_LMH = []\n",
    "all_portafogli_RMW = []\n",
    "all_portafogli_CMA = []\n",
    "\n",
    "combinations_SMB = [(0,0), (0,1), (1,0), (1,1)]\n",
    "combinations_LMH = [(0,0), (1,0), (0,1), (1,1)]\n",
    "combinations_RMW = [(0,1), (1,1), (1,0), (0,0)]\n",
    "combinations_CMA = [(0,0), (1,0), (0,1), (1,1)]\n",
    "\n",
    "# Funzione che crea i portafogli in base alle combinazioni di caratteristiche.\n",
    "def crea_portafogli(characteristics_df, combinations, return_df, col_names):\n",
    "    portafogli = []\n",
    "    for comb in combinations:\n",
    "        selected_stocks = characteristics_df[\n",
    "            (characteristics_df[col_names[0]] == comb[0]) &\n",
    "            (characteristics_df[col_names[1]] == comb[1])\n",
    "        ].index.tolist()\n",
    "\n",
    "        if selected_stocks:  # Verifica che ci siano azioni selezionate.\n",
    "            portfolio_df = return_df[selected_stocks]\n",
    "            portfolio_df.name = f\"{comb[0]}_{comb[1]}\"\n",
    "            portafogli.append(portfolio_df)\n",
    "    return portafogli\n",
    "\n",
    "# Itera su ogni anno nelle liste returns_final_dfs e characteristics_final_dfs.\n",
    "for year_index in range(len(returns_final_dfs)):\n",
    "    # Ottieni i DataFrame di returns e characteristics per l'anno corrente.\n",
    "    returns = returns_final_dfs[year_index]\n",
    "    characteristics = characteristics_final_dfs[year_index]\n",
    "\n",
    "    # Trasponi il DataFrame characteristics e imposta la prima riga come intestazione.\n",
    "    # Manovra necessaria data la forma del dataset.\n",
    "    characteristics_transposed = characteristics.T\n",
    "    characteristics_transposed.columns = characteristics_transposed.iloc[0]\n",
    "    characteristics_transposed = characteristics_transposed[1:]\n",
    "    \n",
    "    # Converte le colonne necessarie in interi.\n",
    "    characteristics_transposed['Size'] = characteristics_transposed['Size'].astype(int)\n",
    "    characteristics_transposed['Value'] = characteristics_transposed['Value'].astype(int)\n",
    "    characteristics_transposed['EBIT'] = characteristics_transposed['EBIT'].astype(int)\n",
    "    characteristics_transposed['INV'] = characteristics_transposed['INV'].astype(int)\n",
    "\n",
    "    characteristics_SMB_1 = characteristics_transposed.iloc[:, :-2]    #df con Size-Value\n",
    "    characteristics_SMB_2 = characteristics_transposed.iloc[:, [0, 2]] #df con Size-Ebit\n",
    "    characteristics_SMB_3 = characteristics_transposed.iloc[:, [0, 3]] #df con Size-INV\n",
    "    characteristics_LMH = characteristics_transposed.iloc[:, :-2]      #df con Value-Size\n",
    "    characteristics_RMW = characteristics_transposed.iloc[:, [0, 2]]   #df con Ebit-Size\n",
    "    characteristics_CMA = characteristics_transposed.iloc[:, [0, 3]]   #df con INV-Size\n",
    "\n",
    "    #Appende i portafogli costruiti dalla funzione \"crea_portafogli\" alle liste.\n",
    "    all_portafogli_SMB_1.append(crea_portafogli(characteristics_SMB_1, combinations_SMB, returns, ['Size', 'Value']))\n",
    "    all_portafogli_SMB_2.append(crea_portafogli(characteristics_SMB_2, combinations_SMB, returns, ['Size', 'EBIT']))\n",
    "    all_portafogli_SMB_3.append(crea_portafogli(characteristics_SMB_3, combinations_SMB, returns, ['Size', 'INV']))\n",
    "    all_portafogli_LMH.append(crea_portafogli(characteristics_LMH, combinations_LMH, returns, ['Size', 'Value']))\n",
    "    all_portafogli_RMW.append(crea_portafogli(characteristics_RMW, combinations_RMW, returns, ['Size', 'EBIT']))\n",
    "    all_portafogli_CMA.append(crea_portafogli(characteristics_CMA, combinations_CMA, returns, ['Size', 'INV']))\n",
    "\n",
    "# Controllo dei numeri di portafogli creati ogni anno (deve essere uno per ogni trimestre)\n",
    "for year_index in range(len(returns_final_dfs)):\n",
    "    print(f\"\\nAnno {year_index + 1}\")\n",
    "    print(f\"Numero totale di portafogli SMB_1 creati: {len(all_portafogli_SMB_1[year_index])}\")\n",
    "    print(f\"Numero totale di portafogli SMB_2 creati: {len(all_portafogli_SMB_2[year_index])}\")\n",
    "    print(f\"Numero totale di portafogli SMB_3 creati: {len(all_portafogli_SMB_3[year_index])}\")\n",
    "    print(f\"Numero totale di portafogli LMH creati: {len(all_portafogli_LMH[year_index])}\")\n",
    "    print(f\"Numero totale di portafogli RMW creati: {len(all_portafogli_RMW[year_index])}\")\n",
    "    print(f\"Numero totale di portafogli CMA creati: {len(all_portafogli_CMA[year_index])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4fa0f-a183-4bd3-88cb-f078e8120b45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calcolo rendimento giornaliero di SMB, LHM, RMW e CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe7e65-5dbb-4271-93d2-009b04f8ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_means_dic_SMB_1 = {}\n",
    "daily_means_dic_SMB_2 = {}\n",
    "daily_means_dic_SMB_3 = {}\n",
    "daily_means_dic_LMH = {}\n",
    "daily_means_dic_RMW = {}\n",
    "daily_means_dic_CMA = {}\n",
    "\n",
    "# Funzione per calcolare le medie giornaliere \"daily_means\" e memorizzarle nell dizionario\n",
    "def calculate_daily_means(all_portafogli, daily_means_dic):\n",
    "    for i, anno in enumerate(all_portafogli, start=1):\n",
    "        daily_means_list = []\n",
    "        for portafoglio in anno:\n",
    "            daily_mean = portafoglio.mean(axis=1)\n",
    "            daily_means_list.append(daily_mean)\n",
    "        daily_means_dic[f'anno_{i}'] = daily_means_list\n",
    "\n",
    "# Calcolo dei daily_means per ciascun portafoglio\n",
    "calculate_daily_means(all_portafogli_SMB_1, daily_means_dic_SMB_1)\n",
    "calculate_daily_means(all_portafogli_SMB_2, daily_means_dic_SMB_2)\n",
    "calculate_daily_means(all_portafogli_SMB_3, daily_means_dic_SMB_3)\n",
    "calculate_daily_means(all_portafogli_LMH, daily_means_dic_LMH)\n",
    "calculate_daily_means(all_portafogli_RMW, daily_means_dic_RMW)\n",
    "calculate_daily_means(all_portafogli_CMA, daily_means_dic_CMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bf43d-d7c7-4f28-82f9-14ec96951701",
   "metadata": {},
   "source": [
    "Una volta calcolate le medie giornaliere tra tutte le stock di ogni caratteristica, si caclcolano i fattori sottraendo le medie.\n",
    "Per quanto riguarda SMB bisogna fare la media di SMB_1, SMB_2 e SMB_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80079f6c-48aa-40bb-b3eb-d5708886f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMB_1_results = {}\n",
    "SMB_2_results = {}\n",
    "SMB_3_results = {}\n",
    "LMH_results = {}\n",
    "RMW_results = {}\n",
    "CMA_results = {}\n",
    "\n",
    "# Funzione per calcolare i fattori\n",
    "def calculate_portfolio_results(daily_means_dict, result_dict, portfolio_name):\n",
    "    for year, daily_means in daily_means_dict.items():\n",
    "        if len(daily_means) >= 4:\n",
    "            # Calcola la media dei primi due portafogli (es. Robust_Big e Robust_Small)\n",
    "            first_portfolio = (daily_means[0] + daily_means[1]) / 2\n",
    "            # Calcola la media dei secondi due portafogli (es. Weak_Big e Weak_Small)\n",
    "            second_portfolio = (daily_means[2] + daily_means[3]) / 2\n",
    "            # Calcola il fattore (es. Robust - Weak)\n",
    "            result = first_portfolio - second_portfolio\n",
    "            result_dict[year] = result\n",
    "        else:\n",
    "            print(f\"Attenzione: meno di 4 portafogli per {year} in {portfolio_name}\")\n",
    "\n",
    "calculate_portfolio_results(daily_means_dic_SMB_1, SMB_1_results, 'SMB_1')\n",
    "calculate_portfolio_results(daily_means_dic_SMB_2, SMB_2_results, 'SMB_2')\n",
    "calculate_portfolio_results(daily_means_dic_SMB_3, SMB_3_results, 'SMB_3')\n",
    "calculate_portfolio_results(daily_means_dic_LMH, LMH_results, 'LMH')\n",
    "calculate_portfolio_results(daily_means_dic_RMW, RMW_results, 'RMW')\n",
    "calculate_portfolio_results(daily_means_dic_CMA, CMA_results, 'CMA')\n",
    "\n",
    "# Calcolo di SMB finale come media dei risultati di SMB_1, SMB_2 e SMB_3\n",
    "SMB_results = {}\n",
    "\n",
    "for year in SMB_1_results.keys():\n",
    "    if year in SMB_2_results and year in SMB_3_results:\n",
    "        SMB_final = (SMB_1_results[year] + SMB_2_results[year] + SMB_3_results[year]) / 3\n",
    "        SMB_results[year] = SMB_final\n",
    "    else:\n",
    "        print(f\"Attenzione: dati non completi per l'anno {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967ba16-e4fa-4e41-9d54-b287f51e2352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calcolo del Fattore di Mercato (Rm-Rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56da669-b6dd-4fc2-b4bb-9c3dfed8f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RmMrf = []\n",
    "\n",
    "for anno in range(len(Rm_dfs)):\n",
    "    Rm = Rm_dfs[anno]\n",
    "    Rf = Rf_dfs[anno]\n",
    "\n",
    "    # Sottrai Rf da Rm, mantenendo solo le date presenti in Rm\n",
    "    Rm_rf = Rm.copy()  # Crea una copia di Rm per preservare l'indice\n",
    "    Rm_rf['Rm-rf'] = Rm['EUSTOXX600'] - Rf['Euribor']\n",
    "    Rm_rf.dropna(subset=['Rm-rf'], inplace=True)\n",
    "\n",
    "    # Appende alla lista solo Rm-Rf\n",
    "    RmMrf.append(Rm_rf[['Rm-rf']])\n",
    "\n",
    "for i, df in enumerate(RmMrf):\n",
    "    print(f\"Anno {i+1} Rm-rf DataFrame:\\n{df}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c613aa-4aa8-482e-9d9e-6204406d2120",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Organizzazione dei Fattori in un unico Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a2d5d-afb8-4025-b0e9-2012a514406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fattori_dfs = []\n",
    "\n",
    "for anno in range(1, 21): \n",
    "    fattori_df = pd.DataFrame()\n",
    "    \n",
    "    fattori_df['Rm-Rf'] = RmMrf[anno - 1]['Rm-rf'] \n",
    "    fattori_df['SMB'] = SMB_results[f'anno_{anno}']\n",
    "    fattori_df['LMH'] = LMH_results[f'anno_{anno}']\n",
    "    fattori_df['RMW'] = RMW_results[f'anno_{anno}']\n",
    "    fattori_df['CMA'] = CMA_results[f'anno_{anno}']\n",
    "    \n",
    "    fattori_dfs.append(fattori_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e302574-18c8-457c-a60e-3ef51bd6a95a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Suddivisione dei Dataframes in trimestri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc4ba8-0ac4-4d4e-9c06-c24c6e5d7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimestri_dfs = {\n",
    "    \"Q3\": [],\n",
    "    \"Q4\": [],\n",
    "    \"Q1\": [],\n",
    "    \"Q2\": []\n",
    "}\n",
    "\n",
    "# Suddivisione dei DataFrame in trimestri\n",
    "for i, fattori_df in enumerate(fattori_dfs):\n",
    "    fattori_df.index = pd.to_datetime(fattori_df.index, dayfirst=True)\n",
    "    \n",
    "    # Filtra i dati in base ai al mese\n",
    "    X_Q3 = fattori_df.loc[(fattori_df.index.month >= 7) & (fattori_df.index.month <= 9)]   # Luglio - Settembre\n",
    "    X_Q4 = fattori_df.loc[(fattori_df.index.month >= 10) & (fattori_df.index.month <= 12)]  # Ottobre - Dicembre\n",
    "    X_Q1 = fattori_df.loc[(fattori_df.index.month >= 1) & (fattori_df.index.month <= 3)]    # Gennaio - Marzo\n",
    "    X_Q2 = fattori_df.loc[(fattori_df.index.month >= 4) & (fattori_df.index.month <= 6)]    # Aprile - Giugno\n",
    "\n",
    "    trimestri_dfs[\"Q3\"].append(X_Q3)\n",
    "    trimestri_dfs[\"Q4\"].append(X_Q4)\n",
    "    trimestri_dfs[\"Q1\"].append(X_Q1)\n",
    "    trimestri_dfs[\"Q2\"].append(X_Q2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a715a9-328b-42b0-a1f9-8b5689f555bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anno in range(1, 21): \n",
    "    print(f\"\\nAnno {anno}:\\n\")\n",
    "    print(\"\\nQ3 (Luglio-Settembre):\")\n",
    "    print(trimestri_dfs[\"Q3\"][anno - 1].head())\n",
    "    print(\"\\nQ4 (Ottobre-Dicembre):\")\n",
    "    print(trimestri_dfs[\"Q4\"][anno - 1].head())\n",
    "    print(\"Q1 (Gennaio-Marzo):\")\n",
    "    print(trimestri_dfs[\"Q1\"][anno - 1].head())\n",
    "    print(\"\\nQ2 (Aprile-Giugno):\")\n",
    "    print(trimestri_dfs[\"Q2\"][anno - 1].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77b4db-f614-4178-b6c7-17723591c2a0",
   "metadata": {},
   "source": [
    "## Costruzione Portafogli LHS\n",
    "Si caricano i dataframe con le caratteristiche delle stock suddivise per terzili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe47d9-676b-4695-9592-f305aaa35690",
   "metadata": {},
   "outputs": [],
   "source": [
    "LHS_characteristics_dfs = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    # Crea i nomi dei file con suffissi\n",
    "    LHS_chara_file = f'LHS_{i}.csv'\n",
    "    LHS_characteristics_df = pd.read_csv(LHS_chara_file, sep=';')\n",
    "\n",
    "    LHS_characteristics_dfs.append(LHS_characteristics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f07e58-018e-4d46-a032-fa3ee4ac2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ripuliscono i dataframe appena caricati sulla base di \"characteristics_final_dfs\"\n",
    "for i in range(len(LHS_characteristics_dfs)):\n",
    "    characteristics_df = characteristics_final_dfs[i]\n",
    "    lhs_df = LHS_characteristics_dfs[i]\n",
    "\n",
    "    columns_to_keep = characteristics_df.columns\n",
    "    # Filtra il DataFrame di LHS per mantenere solo le colonne presenti in characteristics_df\n",
    "    LHS_characteristics_dfs[i] = lhs_df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16c865-6d72-4cf4-ae49-c2e9c26d4ff0",
   "metadata": {},
   "source": [
    "### Creazione Portafogli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7f8ee-b7d6-4df1-ad53-535ef4511b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_portafogli_SizeBM = []\n",
    "all_portafogli_SizeEbit = []\n",
    "all_portafogli_SizeINV = []\n",
    "\n",
    "# Si definiscono le combinazioni per ogni categoria\n",
    "combinations_SizeBM = [(0, 0), (0, 1), (0, 2),\n",
    "                       (1, 0), (1, 1), (1, 2),\n",
    "                       (2, 0), (2, 1), (2, 2)]\n",
    "combinations_SizeEbit = [(0, 0), (0, 1), (0, 2),\n",
    "                         (1, 0), (1, 1), (1, 2),\n",
    "                         (2, 0), (2, 1), (2, 2)]\n",
    "combinations_SizeINV = [(0, 0), (0, 1), (0, 2),\n",
    "                        (1, 0), (1, 1), (1, 2),\n",
    "                        (2, 0), (2, 1), (2, 2)]\n",
    "\n",
    "# Funzione per creare i portafogli per un insieme di combinazioni e caratteristiche specifiche\n",
    "def crea_portafogli(characteristics_df, combinations, return_df, col_names, anno, tipo_portafoglio):\n",
    "    portafogli = []\n",
    "    for comb in combinations:\n",
    "        selected_stocks = characteristics_df[\n",
    "            (characteristics_df[col_names[0]] == comb[0]) &\n",
    "            (characteristics_df[col_names[1]] == comb[1])\n",
    "        ].index.tolist()\n",
    "\n",
    "        if not selected_stocks:  # Se non ci sono azioni selezionate\n",
    "            print(f\"Anno: {anno},  Tipo Portafoglio: {tipo_portafoglio}, Combinazione: {comb} - Nessuna azione trovata\")\n",
    "            missing_counts[tipo_portafoglio][comb] += 1\n",
    "\n",
    "            # Prendi un indice di una stock qualsiasi dal trimestre corrente\n",
    "            if not return_df.empty:  # Assicurati che il DataFrame non sia vuoto\n",
    "                random_stock_index = return_df.columns[0]  # Prendi la prima stock come esempio\n",
    "                portfolio_df = pd.DataFrame(0, index=returns.index, columns=[random_stock_index])  # Tutti i valori a zero\n",
    "                portfolio_df.name = f\"{tipo_portafoglio}_{comb[0]}_{comb[1]}\"\n",
    "                portafogli.append(portfolio_df)\n",
    "        else:  # Se ci sono azioni selezionate\n",
    "            portfolio_df = return_df[selected_stocks]\n",
    "            portfolio_df.name = f\"{tipo_portafoglio}_{comb[0]}_{comb[1]}\"\n",
    "            portafogli.append(portfolio_df)\n",
    "                \n",
    "    return portafogli\n",
    "\n",
    "data = []\n",
    "\n",
    "# Contatore delle mancanze di corrispondenze per ogni portafoglio\n",
    "missing_counts = {\n",
    "    \"Size/BM\": {comb: 0 for comb in combinations_SizeBM},\n",
    "    \"Size/EBIT\": {comb: 0 for comb in combinations_SizeEbit},\n",
    "    \"Size/INV\": {comb: 0 for comb in combinations_SizeINV}\n",
    "}\n",
    "\n",
    "total_years = 20  \n",
    "\n",
    "for year_index in range(len(returns_final_dfs)):\n",
    "    returns = returns_final_dfs[year_index]\n",
    "    characteristics = LHS_characteristics_dfs[year_index]\n",
    "    \n",
    "    anno = f\"Anno {year_index + 1}\"\n",
    "\n",
    "    # Traspone il DataFrame characteristics e imposta la prima riga come intestazione.\n",
    "    characteristics_transposed = characteristics.T\n",
    "    characteristics_transposed.columns = characteristics_transposed.iloc[0]\n",
    "    characteristics_transposed = characteristics_transposed[1:]\n",
    "\n",
    "    characteristics_transposed['Size'] = characteristics_transposed['Size'].astype(int)\n",
    "    characteristics_transposed['Value'] = characteristics_transposed['Value'].astype(int)\n",
    "    characteristics_transposed['EBIT'] = characteristics_transposed['EBIT'].astype(int)\n",
    "    characteristics_transposed['INV'] = characteristics_transposed['INV'].astype(int)\n",
    "\n",
    "    characteristics_SizeBM = characteristics_transposed.iloc[:, :-2]\n",
    "    characteristics_SizeEbit = characteristics_transposed.iloc[:, [0, 2]]\n",
    "    characteristics_SizeINV = characteristics_transposed.iloc[:, [0, 3]]\n",
    "\n",
    "    # Creazione dei portafogli per ogni categoria e aggiunta ai rispettivi elenchi\n",
    "    all_portafogli_SizeBM.append(crea_portafogli(characteristics_SizeBM, combinations_SizeBM, returns, ['Size', 'Value'], anno, \"Size/BM\"))\n",
    "    all_portafogli_SizeEbit.append(crea_portafogli(characteristics_SizeEbit, combinations_SizeEbit, returns, ['Size', 'EBIT'], anno, \"Size/EBIT\"))\n",
    "    all_portafogli_SizeINV.append(crea_portafogli(characteristics_SizeINV, combinations_SizeINV, returns, ['Size', 'INV'], anno, \"Size/INV\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca652061-a4ed-4e54-9cd8-c8ee140ee93b",
   "metadata": {},
   "source": [
    "### Calcolo di statistiche sulla composizione dei portafogli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e659e-67e6-465b-9993-cf6ed2fbba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola il numero di azioni in ogni portafoglio e memorizza i risultati\n",
    "for year_index in range(len(all_portafogli_SizeBM)):\n",
    "    year = f\"Anno {year_index + 1}\"\n",
    "    \n",
    "    for portfolio in all_portafogli_SizeBM[year_index]:\n",
    "        num_stocks = len(portfolio.columns)  \n",
    "        data.append({\"Anno\": year, \"Tipo Portafoglio\": \"Size/BM\", \"Nome Portafoglio\": portfolio.name, \"Numero Azioni\": num_stocks})\n",
    "\n",
    "    for portfolio in all_portafogli_SizeEbit[year_index]:\n",
    "        num_stocks = len(portfolio.columns)\n",
    "        data.append({\"Anno\": year, \"Tipo Portafoglio\": \"Size/EBIT\", \"Nome Portafoglio\": portfolio.name, \"Numero Azioni\": num_stocks})\n",
    "\n",
    "    for portfolio in all_portafogli_SizeINV[year_index]:\n",
    "        num_stocks = len(portfolio.columns)\n",
    "        data.append({\"Anno\": year, \"Tipo Portafoglio\": \"Size/INV\", \"Nome Portafoglio\": portfolio.name, \"Numero Azioni\": num_stocks})\n",
    "\n",
    "# Calcola la percentuale di trimestri in cui sono presenti stock selezionate\n",
    "for tipo_portafoglio, combinations in missing_counts.items():\n",
    "    for comb, count in combinations.items():\n",
    "        present_years = total_years - count \n",
    "        percentuale = (present_years / total_years) * 100  \n",
    "\n",
    "        data.append({\"Anno\": \"Totale\", \"Tipo Portafoglio\": tipo_portafoglio, \"Combinazione\": comb, \"Percentuale Anni con Stock\": percentuale})\n",
    "\n",
    "# Crea un DataFrame con i risultati\n",
    "portafogli_df = pd.DataFrame(data)\n",
    "\n",
    "output_file = 'portafogli_azioni_percentuale_trimestri.xlsx'\n",
    "portafogli_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"File Excel creato: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7645b9-6f8d-4d18-b783-117383b22839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare le medie giornaliere e popolare il dizionario\n",
    "def calculate_daily_means(all_portafogli, daily_means_dic):\n",
    "    for i, anno in enumerate(all_portafogli, start=1):\n",
    "        daily_means_list = [portafoglio.mean(axis=1) for portafoglio in anno]\n",
    "        daily_means_dic[f'anno_{i}'] = daily_means_list\n",
    "\n",
    "daily_means_dic_SizeBM = {}\n",
    "daily_means_dic_SizeEbit = {}\n",
    "daily_means_dic_SizeINV = {}\n",
    "\n",
    "calculate_daily_means(all_portafogli_SizeBM, daily_means_dic_SizeBM)\n",
    "calculate_daily_means(all_portafogli_SizeEbit, daily_means_dic_SizeEbit)\n",
    "calculate_daily_means(all_portafogli_SizeINV, daily_means_dic_SizeINV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d583ae-fad6-4bfe-97e6-e7dbd3531ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare i risultati della sottrazione (Rm-Rf)\n",
    "def calculate_RMRf(daily_means_dic, Rf_dfs):\n",
    "    RMRf_dic = {}\n",
    "    for key, df_list in daily_means_dic.items():\n",
    "        adjusted_df_list = []\n",
    "\n",
    "        # Estrai l'indice dall'intestazione della chiave (es: 'anno_1' -> 0)\n",
    "        year_index = int(key.split('_')[1]) - 1  \n",
    "\n",
    "        # Ottieni il DataFrame corrispondente in Rf_dfs\n",
    "        rf_df = Rf_dfs[year_index]  \n",
    "\n",
    "        for df in df_list:\n",
    "            rf_aligned = rf_df['Euribor'].reindex(df.index)  # Allinea rf_df['Euribor'] agli indici di df\n",
    "            adjusted_df = df - rf_aligned  # Sottrai i valori allineati\n",
    "            adjusted_df_list.append(adjusted_df)\n",
    "\n",
    "        RMRf_dic[key] = adjusted_df_list\n",
    "\n",
    "    return RMRf_dic\n",
    "\n",
    "# Calcolo dei risultati RMRf per ogni gruppo di portafogli\n",
    "RMRf_SizeBM = calculate_RMRf(daily_means_dic_SizeBM, Rf_dfs)\n",
    "RMRf_SizeEbit = calculate_RMRf(daily_means_dic_SizeEbit, Rf_dfs)\n",
    "RMRf_SizeINV = calculate_RMRf(daily_means_dic_SizeINV, Rf_dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f436ddb-d27f-4848-979b-4dfc59126df0",
   "metadata": {},
   "source": [
    "Suddivisione dei portafogli in trimestri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3874acb-2d1b-4af8-b4ed-59c9f4be863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SizeBM = {f\"anno_{i}\": {\"Q1\": [], \"Q2\": [], \"Q3\": [], \"Q4\": []} for i in range(1, 21)}\n",
    "y_SizeEbit = {f\"anno_{i}\": {\"Q1\": [], \"Q2\": [], \"Q3\": [], \"Q4\": []} for i in range(1, 21)}\n",
    "y_SizeINV = {f\"anno_{i}\": {\"Q1\": [], \"Q2\": [], \"Q3\": [], \"Q4\": []} for i in range(1, 21)}\n",
    "\n",
    "# Funzione per suddividere i DataFrame in trimestri\n",
    "def suddividi_in_trimestri(daily_means_dic, output_dic):\n",
    "    for year_index, (key, df_list) in enumerate(daily_means_dic.items()):\n",
    "        for portfolio_df in df_list:\n",
    "            portfolio_df.index = pd.to_datetime(portfolio_df.index, dayfirst=True)\n",
    "\n",
    "            # Dividi i dati in trimestri sulla base dei mesi\n",
    "            X_Q3 = portfolio_df.loc[(portfolio_df.index.month >= 7) & (portfolio_df.index.month <= 9)]   # Luglio - Settembre\n",
    "            X_Q4 = portfolio_df.loc[(portfolio_df.index.month >= 10) & (portfolio_df.index.month <= 12)]  # Ottobre - Dicembre\n",
    "            X_Q1 = portfolio_df.loc[(portfolio_df.index.month >= 1) & (portfolio_df.index.month <= 3)]    # Gennaio - Marzo\n",
    "            X_Q2 = portfolio_df.loc[(portfolio_df.index.month >= 4) & (portfolio_df.index.month <= 6)]    # Aprile - Giugno\n",
    "\n",
    "            output_dic[key][\"Q3\"].append(X_Q3)\n",
    "            output_dic[key][\"Q4\"].append(X_Q4)\n",
    "            output_dic[key][\"Q1\"].append(X_Q1)\n",
    "            output_dic[key][\"Q2\"].append(X_Q2)\n",
    "\n",
    "suddividi_in_trimestri(daily_means_dic_SizeBM, y_SizeBM)\n",
    "suddividi_in_trimestri(daily_means_dic_SizeEbit, y_SizeEbit)\n",
    "suddividi_in_trimestri(daily_means_dic_SizeINV, y_SizeINV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2bf141-31bc-4886-aa4b-9824ecd7f103",
   "metadata": {},
   "source": [
    "## Regressioni di FF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9707edc-1902-4ae2-bbc5-f347824de864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.stats.stattools import durbin_watson, jarque_bera\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512e033-647b-49fa-bf11-2551a9c64603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare e salvare le statistiche delle regressioni \n",
    "def salva_statistiche_regressione(y_data, x_data, label, risultati, conteggi):\n",
    "    for anno, trimestri in y_data.items():\n",
    "        for trimestre in [\"Q3\", \"Q4\", \"Q1\", \"Q2\"]:\n",
    "            for i, y in enumerate(trimestri[trimestre]):\n",
    "                if not x_data[trimestre][int(anno.split(\"_\")[1]) - 1].empty and not y.empty:\n",
    "                    X = x_data[trimestre][int(anno.split(\"_\")[1]) - 1]\n",
    "                    X = sm.add_constant(X)  \n",
    "                    y_aligned, X_aligned = y.align(X, join='inner', axis=0)\n",
    "\n",
    "                    portafoglio_key = f\"Portafoglio_{i + 1}\"\n",
    "\n",
    "                    #Dizionario per raccolta delle statistiche.\n",
    "                    if portafoglio_key not in conteggi:\n",
    "                        conteggi[portafoglio_key] = {\n",
    "                            \"OLS\": 0,\n",
    "                            \"RLM\": 0,\n",
    "                            \"Residui Non Normali\": 0,\n",
    "                            \"Eteroschedasticità\": 0,\n",
    "                            \"OLS con HC3\": 0,  \n",
    "                            \"Regressioni Totali\": 0,  \n",
    "                        }\n",
    "                    # conteggio delle regressioni totali\n",
    "                    conteggi[portafoglio_key][\"Regressioni Totali\"] += 1\n",
    "\n",
    "                    # Esegui il modello OLS per poi effettuare White test e Jarque Bera test seui residui\n",
    "                    modello = sm.OLS(y_aligned, X_aligned).fit()\n",
    "                    jb_test = jarque_bera(modello.resid)\n",
    "                    white_test = het_white(modello.resid, modello.model.exog)\n",
    "\n",
    "                    # Flag per scegliere RLM se i residui non sono normali\n",
    "                    utilizzo_rlm = jb_test[1] < 0.05  \n",
    "                    \n",
    "                    # Se c'è eteroschedasticità utilizza la matric di covarianza HC3.\n",
    "                    if white_test[1] < 0.05:\n",
    "                        modello_robusto = sm.OLS(y_aligned, X_aligned).fit(cov_type='HC3')\n",
    "                        alpha = modello_robusto.params.get('const', None)\n",
    "                        pvalues_alpha = modello_robusto.pvalues.get('const', None)\n",
    "                        r_squared = modello_robusto.rsquared\n",
    "                        conteggi[portafoglio_key][\"Eteroschedasticità\"] += 1\n",
    "                        conteggi[portafoglio_key][\"OLS con HC3\"] += 1  # Incrementa OLS con HC3\n",
    "                        coeff_regressori = modello_robusto.params.drop('const') if 'const' in modello_robusto.params else modello_robusto.params\n",
    "                        pvalues = modello_robusto.pvalues\n",
    "\n",
    "                    # Se non c'è eteroschedasticità e i residui sono normali utilizza il modello OLS.\n",
    "                    elif not utilizzo_rlm:\n",
    "                        alpha = modello.params.get('const', None)\n",
    "                        pvalues_alpha = modello.pvalues.get('const', None)\n",
    "                        r_squared = modello.rsquared\n",
    "                        conteggi[portafoglio_key][\"OLS\"] += 1  # Incrementa OLS\n",
    "                        coeff_regressori = modello.params.drop('const') if 'const' in modello.params else modello.params\n",
    "                        pvalues = modello.pvalues\n",
    "\n",
    "                    # Se ci sono residui non normali, esegui RLM\n",
    "                    elif utilizzo_rlm:\n",
    "                        modello_rlm = sm.RLM(y_aligned, X_aligned).fit()\n",
    "                        alpha = modello_rlm.params.get('const', None)\n",
    "                        pvalues_alpha = modello_rlm.pvalues.get('const', None)  # Non c'è p-value per RLM\n",
    "                        r_squared_adj = None  # Imposta a None per i modelli RLM\n",
    "                        if sum((y_aligned - y_aligned.mean()) ** 2) == 0:\n",
    "                            pseudo_r_squared = None  \n",
    "                        else:\n",
    "                            pseudo_r_squared = 1 - (sum(modello_rlm.resid ** 2) / sum((y_aligned - y_aligned.mean()) ** 2))\n",
    "                        conteggi[portafoglio_key][\"Residui Non Normali\"] += 1  # Incrementa residui non normali\n",
    "                        conteggi[portafoglio_key][\"RLM\"] += 1  # Incrementa RLM\n",
    "                        coeff_regressori = modello_rlm.params.drop('const') if 'const' in modello_rlm.params else modello_rlm.params\n",
    "                        pvalues = modello_rlm.pvalues  # Non c'è p-value per RLM\n",
    "\n",
    "                    # Test di Durbin-Watson sui residui.\n",
    "                    durbin_watson_test = durbin_watson(modello.resid)\n",
    "\n",
    "                    risultati.append({\n",
    "                        \"Anno\": anno,\n",
    "                        \"Trimestre\": trimestre,\n",
    "                        \"Portafoglio\": portafoglio_key,\n",
    "                        \"Alpha\": alpha,\n",
    "                        \"P-value Alpha\": pvalues_alpha,\n",
    "                        \"R²\": r_squared,\n",
    "                        \"Pseudo R²\": pseudo_r_squared if utilizzo_rlm else None,\n",
    "                        \"Jarque-Bera P-value\": jb_test[1],\n",
    "                        \"White P-value\": white_test[1],\n",
    "                        \"Durbin-Watson\": durbin_watson_test,\n",
    "                        \"Tipo di Modello\": \"RLM\" if utilizzo_rlm else \"OLS\"\n",
    "                    })\n",
    "\n",
    "                    # Aggiungi i coefficienti dei regressori e i p-value\n",
    "                    if coeff_regressori is not None:\n",
    "                        for nome_regressore, coeff in coeff_regressori.items():\n",
    "                            risultati[-1][f\"Coeff {nome_regressore}\"] = coeff\n",
    "                            risultati[-1][f\"P-value {nome_regressore}\"] = pvalues[nome_regressore] if pvalues is not None else None\n",
    "\n",
    "    return risultati, conteggi\n",
    "\n",
    "# Funzione principale aggiornata per calcolare percentuali OLS con cov_type=HC3\n",
    "def esegui_regressioni(y_data_list, x_data_list, labels, filename):\n",
    "    risultati = []\n",
    "    \n",
    "    with pd.ExcelWriter(filename) as writer:\n",
    "        for y_data, x_data, label in zip(y_data_list, x_data_list, labels):\n",
    "            conteggi = {} \n",
    "            #Esegue funzione salva_statistiche_regressione:\n",
    "            # \"risultati\" contiene coefficienti e p-values, \"conteggi\" contiene i numeri di regressioni.\n",
    "            risultati, conteggi = salva_statistiche_regressione(y_data, x_data, label, risultati, conteggi)\n",
    "\n",
    "            # Calcola percentuali di utilizzo.\n",
    "            percentuali = []\n",
    "            for portafoglio, stats in conteggi.items():\n",
    "                totale = stats[\"Regressioni Totali\"]\n",
    "                percentuali.append({\n",
    "                    \"Portafoglio\": portafoglio,\n",
    "                    \"Percentuale OLS\": (stats[\"OLS\"] / totale) * 100 if totale > 0 else 0,\n",
    "                    \"Percentuale RLM\": (stats[\"RLM\"] / totale) * 100 if totale > 0 else 0,\n",
    "                    \"Percentuale OLS con HC3\": (stats[\"OLS con HC3\"] / totale) * 100 if totale > 0 else 0,\n",
    "                    \"Percentuale Residui Non Normali\": (stats[\"Residui Non Normali\"] / totale) * 100 if totale > 0 else 0,\n",
    "                    \"Percentuale Eteroschedasticità\": (stats[\"Eteroschedasticità\"] / totale) * 100 if totale > 0 else 0,\n",
    "                    \"Numero Residui Non Normali\": stats[\"Residui Non Normali\"],  \n",
    "                    \"Regressioni Totali\": stats[\"Regressioni Totali\"]  \n",
    "                })\n",
    "\n",
    "            percentuali_df = pd.DataFrame(percentuali)\n",
    "\n",
    "            # Download di file excel per risultati e statistiche.\n",
    "            risultati_df = pd.DataFrame(risultati)\n",
    "            risultati_df.to_excel(writer, sheet_name=f'Risultati_{label}', index=False)\n",
    "            percentuali_df.to_excel(writer, sheet_name=f'Percentuali_{label}', index=False)\n",
    "\n",
    "            for portafoglio, stats in conteggi.items():\n",
    "                totale = stats[\"Regressioni Totali\"]\n",
    "                percentuale_residui_non_normali = (stats[\"Residui Non Normali\"] / totale) * 100 if totale > 0 else 0\n",
    "                percentuale_ols_hc3 = (stats[\"OLS con HC3\"] / totale) * 100 if totale > 0 else 0\n",
    "                print(f\"{portafoglio}: {stats['Residui Non Normali']} residui non normali, \"\n",
    "                      f\"{percentuale_residui_non_normali:.2f}% dei casi, {percentuale_ols_hc3:.2f}% OLS con HC3, \"\n",
    "                      f\"{stats['Regressioni Totali']} regressioni totali\")\n",
    "\n",
    "# Esegui la funzione per ogni gruppo di portafogli.\n",
    "esegui_regressioni([y_SizeBM, y_SizeEbit, y_SizeINV], [trimestri_dfs, trimestri_dfs, trimestri_dfs], [\"SizeBM\", \"SizeEbit\", \"SizeINV\"], \"statistiche_completato.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b5761-cc64-4cbf-93b7-a26b19972afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i risultati dai file Excel\n",
    "risultati_SizeBM = pd.read_excel(\"statistiche_SizeBM.xlsx\")\n",
    "risultati_SizeEbit = pd.read_excel(\"statistiche_SizeEbit.xlsx\")\n",
    "risultati_SizeINV = pd.read_excel(\"statistiche_SizeINV.xlsx\")\n",
    "\n",
    "# Funzione per creare una heatmap degli alpha per trimestre e portafoglio\n",
    "def heatmap_alpha_trimestrale(risultati_df, titolo=\"Heatmap degli Alpha per Trimestre\"):\n",
    "    # Crea una tabella pivot per i valori di alpha con portafoglio e trimestre\n",
    "    alpha_trimestrali = risultati_df.pivot_table(values=\"Alpha\", index=[\"Anno\", \"Trimestre\"], columns=\"Portafoglio\")\n",
    "\n",
    "    # Crea la heatmap degli alpha trimestrali\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Imposta il formato come percentuale con due decimali\n",
    "    sns.heatmap(alpha_trimestrali * 100, \n",
    "                annot=alpha_trimestrali.applymap(lambda x: f\"{x * 100:.2f}%\" if pd.notnull(x) else \"\"), \n",
    "                fmt=\"\", \n",
    "                cmap=\"coolwarm\", \n",
    "                cbar_kws={'label': 'Valore Alpha (%)'})\n",
    "\n",
    "    # Titolo e visualizzazione della heatmap\n",
    "    plt.title(titolo, fontsize=16, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Portafoglio\")\n",
    "    plt.ylabel(\"Anno e Trimestre\")\n",
    "    plt.xticks(rotation=45)  # Ruota le etichette delle colonne per leggibilità\n",
    "    plt.show()\n",
    "\n",
    "    return alpha_trimestrali  # Ritorna la tabella degli alpha trimestrali per uso successivo\n",
    "\n",
    "# Funzione per calcolare e visualizzare la correlazione tra gli alpha trimestrali\n",
    "def heatmap_correlation_alpha(alpha_trimestrali_df, titolo=\"Heatmap delle Correlazioni tra Alpha Trimestrali\"):\n",
    "    # Calcola la matrice di correlazione\n",
    "    corr_matrix = alpha_trimestrali_df.corr()\n",
    "\n",
    "    # Crea la heatmap delle correlazioni\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"viridis\", cbar_kws={'label': 'Correlazione'})\n",
    "\n",
    "    # Titolo e visualizzazione della heatmap\n",
    "    plt.title(titolo, fontsize=16, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Portafoglio\")\n",
    "    plt.ylabel(\"Portafoglio\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualizza la heatmap degli alpha trimestrali per ciascun file di risultati\n",
    "alpha_trimestrali_SizeBM = heatmap_alpha_trimestrale(risultati_SizeBM, titolo=\"Heatmap degli Alpha per Trimestre - SizeBM\")\n",
    "alpha_trimestrali_SizeEbit = heatmap_alpha_trimestrale(risultati_SizeEbit, titolo=\"Heatmap degli Alpha per Trimestre - SizeEbit\")\n",
    "alpha_trimestrali_SizeINV = heatmap_alpha_trimestrale(risultati_SizeINV, titolo=\"Heatmap degli Alpha per Trimestre - SizeINV\")\n",
    "\n",
    "# Visualizza le correlazioni tra gli alpha trimestrali per ciascun set di risultati\n",
    "heatmap_correlation_alpha(alpha_trimestrali_SizeBM, titolo=\"Heatmap delle Correlazioni tra Alpha Trimestrali - SizeBM\")\n",
    "heatmap_correlation_alpha(alpha_trimestrali_SizeEbit, titolo=\"Heatmap delle Correlazioni tra Alpha Trimestrali - SizeEbit\")\n",
    "heatmap_correlation_alpha(alpha_trimestrali_SizeINV, titolo=\"Heatmap delle Correlazioni tra Alpha Trimestrali - SizeINV\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
