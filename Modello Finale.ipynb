{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f108d8-f0fb-47c3-82ac-5daa2e3adc22",
   "metadata": {},
   "source": [
    "# MM4 e Calcolo Risk Premia\n",
    "Questo codice deve essere lanciato due volte, una con le componenti principali costruite con le variabili grezze e una con le componenti principali costruite con gli shock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63c9945-9238-472d-99e6-c8b5a5568e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be4070-8034-4bf3-8bfc-904fad0a1786",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Alpha di Fama e French Five Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df29c6-88c1-4494-8c8b-20a97b23fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\"Germania\", \"Francia\", \"Italia\", \"Spagna\", \"Finlandia\", \"Olanda\"]\n",
    "file_names = [\"a_SizeBM\", \"a_SizeEbit\", \"a_SizeINV\"]\n",
    "\n",
    "# Percorso dei file\n",
    "base_folder = \"/Users/nome/****/****\"\n",
    "\n",
    "alpha = {}\n",
    "Alpha = {} # SarÃ  utile poi per calcolare i fattori macroeconomici.\n",
    "\n",
    "# Definisci i nomi dei portafogli.\n",
    "portfolio_names = [f\"Portafoglio_{i}\" for i in range(1, 10)]\n",
    "\n",
    "# Itera su ogni paese e file\n",
    "for country in countries:\n",
    "    for file_name in file_names:\n",
    "        file_path = f\"{base_folder}/{country}/****/{file_name}.pkl\"\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_pickle(file_path)\n",
    "            print(f\"Dati caricati per {country} - {file_name}.\")\n",
    "            Alpha[f\"{country}_{file_name}\"] = df\n",
    "\n",
    "            # Si suddividono gli alpha per portafogli.\n",
    "            a = {}\n",
    "            for year, quarters in df.items():  \n",
    "                a[year] = {}  \n",
    "\n",
    "                for quarter, values in quarters.items():\n",
    "                    a[year][quarter] = dict(zip(portfolio_names, values))\n",
    "            \n",
    "            alpha[f\"{country}_{file_name}\"] = a\n",
    "        else:\n",
    "            print(f\"File non trovato: {file_path}\")\n",
    "\n",
    "# Esempio di accesso ai dati rinominati\n",
    "print(alpha['Germania_a_SizeBM']['anno_1']['Q1']['Portafoglio_1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accaf14e-e171-49fc-a237-7b4d54f46a38",
   "metadata": {},
   "source": [
    "Si calcolano per ogni portafoglio le medie degli alpha a livello europeo nei 20 anni e si visualizzano (facoltativo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daec351-630f-4dbd-974a-2d41ee412624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario per accumulare i dati delle nazioni e calcolare la media\n",
    "alpha['Europa'] = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "for file_key in file_keys:\n",
    "    for year in alpha[f'{countries[0]}_{file_key}']: \n",
    "        for quarter in alpha[f'{countries[0]}_{file_key}'][year]: \n",
    "            \n",
    "            # Media per ogni portafoglio\n",
    "            portfolio_sums = defaultdict(float)\n",
    "            count = 0\n",
    "\n",
    "            # Somma i valori di ogni portafoglio per ogni paese\n",
    "            for country in countries:\n",
    "                country_key = f\"{country}_{file_key}\"\n",
    "                \n",
    "                if quarter in alpha[country_key][year]:\n",
    "                    for portfolio, value in alpha[country_key][year][quarter].items():\n",
    "                        portfolio_sums[portfolio] += value\n",
    "                    count += 1\n",
    "\n",
    "            # Calcola la media per ogni portafoglio e aggiungila ai dati di Europa\n",
    "            for portfolio, total in portfolio_sums.items():\n",
    "                if count > 0:\n",
    "                    alpha['Europa'][file_key][year][quarter][portfolio] = total / count\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e24909-ea5f-4885-a27c-1548a5cf92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = [f'Portafoglio_{i+1}' for i in range(9)]\n",
    "categories = ['a_SizeBM', 'a_SizeEbit', 'a_SizeINV']\n",
    "years = [f'anno_{i+1}' for i in range(1, 21)]\n",
    "\n",
    "# Funzione per calcolare la media degli alpha su 20 anni e creare la heatmap\n",
    "def heatmap_alpha_medi_su_20_anni(alpha_data, category, title):\n",
    "    alpha_medi_20_anni = {}\n",
    "\n",
    "    # Calcola la media annuale per ogni portafoglio per la categoria\n",
    "    for portfolio in portfolios:\n",
    "        annual_means = []\n",
    "        for year in years:\n",
    "            quarterly_values = [\n",
    "                alpha_data['Europa'][category][year].get(quarter, {}).get(portfolio, None)\n",
    "                for quarter in ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "            ]\n",
    "            quarterly_values = [v for v in quarterly_values if v is not None]\n",
    "            if quarterly_values:\n",
    "                annual_means.append(sum(quarterly_values) / len(quarterly_values))\n",
    "        \n",
    "        # Calcola la media dei 20 anni\n",
    "        if annual_means:\n",
    "            alpha_medi_20_anni[portfolio] = sum(annual_means) / len(annual_means)\n",
    "    \n",
    "    # Converti i dati in un DataFrame per la heatmap\n",
    "    alpha_medi_20_anni_df = pd.DataFrame([alpha_medi_20_anni], index=[category])\n",
    "\n",
    "    # Crea la heatmap\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    sns.heatmap(alpha_medi_20_anni_df, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar_kws={'label': 'Valore Medio Alpha'})\n",
    "    plt.title(title, fontsize=16, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Portafoglio\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.show()\n",
    "\n",
    "# Genera le heatmap per ciascuna categoria\n",
    "for category in categories:\n",
    "    heatmap_alpha_medi_su_20_anni(alpha, category, f\"Heatmap degli Alpha Medi Aggregati - {category}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd6d5e-8c9b-4ffe-8769-cecfa132813c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import degli Indicatori Macroeconomici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7fe69-c734-4a73-b399-eb39ea3568ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"pc1_shock_all_nations\", \"pc2_shock_all_nations\", \"pc3_shock_all_nations\", \"pc4_shock_all_nations\"]\n",
    "\n",
    "# Cartella base del percorso\n",
    "base_folder = \"/Users/micha/****/****/****\"\n",
    "\n",
    "Shock = {}\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = f\"{base_folder}/{file_name}.pkl\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_pickle(file_path)\n",
    "        print(df)\n",
    "        df = df.dropna()\n",
    "        Shock[f\"{file_name}\"] = df\n",
    "        print(f\"Dati caricati per {file_name}.\")\n",
    "    else:\n",
    "        print(f\"File non trovato: {file_path}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df75da-f0d1-4e55-b067-c4688034f23e",
   "metadata": {},
   "source": [
    "Ristrutturazione del dizionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f52b0-d96c-4d97-a228-01cf6caebfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per ristrutturare i dati\n",
    "def restructure_data(shock_data):\n",
    "    # Inizializza il dizionario principale per Shock\n",
    "    Shock_final = {\n",
    "        'PC1': {},\n",
    "        'PC2': {},\n",
    "        'PC3': {},\n",
    "        'PC4': {},\n",
    "    }\n",
    "    \n",
    "    # Estrae i dati di produzione, spread e inflazione\n",
    "    PC1 = shock_data['pc1_shock_all_nations']\n",
    "    PC2 = shock_data['pc2_shock_all_nations']\n",
    "    PC3 = shock_data['pc3_shock_all_nations']\n",
    "    PC4 = shock_data['pc4_shock_all_nations']\n",
    "    \n",
    "    def extract_data(data, category_name):\n",
    "        \"\"\"Funzione interna per estrarre i dati trimestrali.\"\"\"\n",
    "        for country in data.columns:\n",
    "            country_years = {}\n",
    "            values = data[country].values\n",
    "            \n",
    "            for i in range(0, len(values), 4):\n",
    "                year_index = i // 4 + 1  \n",
    "                year_key = f'anno_{year_index}'\n",
    "                \n",
    "                # Crea un dizionario per l'anno \n",
    "                if year_key not in country_years:\n",
    "                    country_years[year_key] = {\n",
    "                        'Q3': [],  \n",
    "                        'Q4': [],  \n",
    "                        'Q1': [],  \n",
    "                        'Q2': []  \n",
    "                    }\n",
    "                \n",
    "                # Aggiunge i dati ai trimestri\n",
    "                if i < len(values):  # Q3\n",
    "                    country_years[year_key]['Q3'].append(values[i])\n",
    "                if i + 1 < len(values):  # Q4\n",
    "                    country_years[year_key]['Q4'].append(values[i + 1])\n",
    "                if i + 2 < len(values):  # Q1\n",
    "                    country_years[year_key]['Q1'].append(values[i + 2])\n",
    "                if i + 3 < len(values):  # Q2\n",
    "                    country_years[year_key]['Q2'].append(values[i + 3])\n",
    "            \n",
    "            # Aggiunge i dati della nazione al dizionario finale\n",
    "            Shock_final[category_name][country] = country_years\n",
    "\n",
    "\n",
    "    # Estrai i dati per ogni categoria\n",
    "    extract_data(PC1, 'PC1')\n",
    "    extract_data(PC2, 'PC2')\n",
    "    extract_data(PC3, 'PC3')\n",
    "    extract_data(PC4, 'PC4')\n",
    "\n",
    "    return Shock_final\n",
    "\n",
    "# Creia il nuovo dizionario Shock\n",
    "restructured_shock = restructure_data(Shock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550aeab-9096-4c8d-b29e-3134a8349004",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calcolo dei Fattori Macroeconomici\n",
    "Si calcola per ogni periodo la media degli alpha tra tutti i portafogli di ogni nazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ad5a1-0710-44e0-94b2-fcfe77a86194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dizionario per contenere le medie\n",
    "media_alpha = {}\n",
    "\n",
    "# Elenco delle nazioni e portafogli\n",
    "nazioni = ['Germania', 'Francia', 'Italia', 'Spagna', 'Finlandia', 'Olanda']\n",
    "portafogli = ['SizeBM', 'SizeEbit', 'SizeINV']\n",
    "\n",
    "# Per ogni nazione\n",
    "for nazione in nazioni:\n",
    "    media_alpha[nazione] = {}\n",
    "\n",
    "    # Per ogni anno\n",
    "    for anno in range(1, 21):  \n",
    "        anno_key = f'anno_{anno}'\n",
    "        media_alpha[nazione][anno_key] = {}\n",
    "        \n",
    "        rendimenti_Q3 = []\n",
    "        rendimenti_Q4 = []\n",
    "        rendimenti_Q1 = []\n",
    "        rendimenti_Q2 = []\n",
    "\n",
    "        # Per ogni categoria di portafoglio (es. SizeBM)\n",
    "        for size in portafogli:\n",
    "            portafoglio_key = f'{nazione}_a_{size}'  \n",
    "            if portafoglio_key in alpha:\n",
    "\n",
    "                # Per ogni portafoglio\n",
    "                for n in range(1,10):\n",
    "                    portafoglio = f'Portafoglio_{n}'\n",
    "                # Accumula i rendimenti per i trimestri\n",
    "                rendimenti_Q3.append(alpha[portafoglio_key][anno_key]['Q3'][portafoglio])\n",
    "                rendimenti_Q4.append(alpha[portafoglio_key][anno_key]['Q4'][portafoglio])\n",
    "                rendimenti_Q1.append(alpha[portafoglio_key][anno_key]['Q1'][portafoglio])\n",
    "                rendimenti_Q2.append(alpha[portafoglio_key][anno_key]['Q2'][portafoglio])\n",
    "\n",
    "        # Calcola la media tra i portafogli di tutte le categorie di ogni nazione per ogni trimestre\n",
    "        media_alpha[nazione][anno_key]['Q3'] = np.mean(rendimenti_Q3) if rendimenti_Q3 else None\n",
    "        media_alpha[nazione][anno_key]['Q4'] = np.mean(rendimenti_Q4) if rendimenti_Q4 else None\n",
    "        media_alpha[nazione][anno_key]['Q1'] = np.mean(rendimenti_Q1) if rendimenti_Q1 else None\n",
    "        media_alpha[nazione][anno_key]['Q2'] = np.mean(rendimenti_Q2) if rendimenti_Q2 else None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba09aad-36e9-406b-afba-ef614a793782",
   "metadata": {},
   "source": [
    "Si trovano per ogni periodo i paesi con componente principale sopra e sotto alla mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae608f9-b1f0-48b8-91ab-7ec6ba7d197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare \"above\" e \"below\" \n",
    "def calcola_above_below(variabili):\n",
    "    # Ordina i paesi in base ai valori e seleziona i primi 3 e gli ultimi 3\n",
    "    ordinato = sorted(variabili, key=lambda x: x[1], reverse=True)  \n",
    "    above = [x[0] for x in ordinato[:3]]  \n",
    "    below = [x[0] for x in ordinato[3:]]  \n",
    "    return above, below\n",
    "\n",
    "# Dizionari per memorizzare i fattori\n",
    "PC1_factors = {year: {} for year in range(1, 21)}\n",
    "PC2_factors = {year: {} for year in range(1, 21)}\n",
    "PC3_factors = {year: {} for year in range(1, 21)}\n",
    "PC4_factors = {year: {} for year in range(1, 21)}\n",
    "\n",
    "# Dizionari per il calcolo delle statistiche\n",
    "above_counts = {'PC1': {}, 'PC2': {}, 'PC3': {}, 'PC4': {}}\n",
    "below_counts = {'PC1': {}, 'PC2': {}, 'PC3': {}, 'PC4': {}}\n",
    "\n",
    "# Per ogni anno\n",
    "for year in range(1, 21):\n",
    "    # Per ogni trimestre\n",
    "    for quarter in ['Q3', 'Q4', 'Q1', 'Q2']:\n",
    "        pc1_values = []\n",
    "        pc2_values = []\n",
    "        pc3_values = []\n",
    "        pc4_values = []\n",
    "        # Per ogni paese\n",
    "        for country in restructured_shock['PC1']:\n",
    "            pc1_value = restructured_shock['PC1'][country][f'anno_{year}'][quarter][0]\n",
    "            pc1_values.append((country, pc1_value))\n",
    "\n",
    "            pc2_value = restructured_shock['PC2'][country][f'anno_{year}'][quarter][0]\n",
    "            pc2_values.append((country, pc2_value))\n",
    "\n",
    "            pc3_value = restructured_shock['PC3'][country][f'anno_{year}'][quarter][0]\n",
    "            pc3_values.append((country, pc3_value))\n",
    "\n",
    "            pc4_value = restructured_shock['PC4'][country][f'anno_{year}'][quarter][0]\n",
    "            pc4_values.append((country, pc4_value))\n",
    "\n",
    "        # Calcolare i paesi sopra e sotto la mediana\n",
    "        above_pc1, below_pc1 = calcola_above_below(pc1_values)\n",
    "        above_pc2, below_pc2 = calcola_above_below(pc2_values)\n",
    "        above_pc3, below_pc3 = calcola_above_below(pc3_values)\n",
    "        above_pc4, below_pc4 = calcola_above_below(pc4_values)\n",
    "\n",
    "        # Aggiorna i conteggi per ciascun paese\n",
    "        for country in above_pc1:\n",
    "            above_counts['PC1'][country] = above_counts['PC1'].get(country, 0) + 1\n",
    "        for country in below_pc1:\n",
    "            below_counts['PC1'][country] = below_counts['PC1'].get(country, 0) + 1\n",
    "\n",
    "        for country in above_pc2:\n",
    "            above_counts['PC2'][country] = above_counts['PC2'].get(country, 0) + 1\n",
    "        for country in below_pc2:\n",
    "            below_counts['PC2'][country] = below_counts['PC2'].get(country, 0) + 1\n",
    "\n",
    "        for country in above_pc3:\n",
    "            above_counts['PC3'][country] = above_counts['PC3'].get(country, 0) + 1\n",
    "        for country in below_pc3:\n",
    "            below_counts['PC3'][country] = below_counts['PC3'].get(country, 0) + 1\n",
    "\n",
    "        for country in above_pc4:\n",
    "            above_counts['PC4'][country] = above_counts['PC4'].get(country, 0) + 1\n",
    "        for country in below_pc4:\n",
    "            below_counts['PC4'][country] = below_counts['PC4'].get(country, 0) + 1\n",
    "\n",
    "        # Calcolo dei fattori di PC1, PC2, PC3, PC4 per il trimestre e l'anno corrente\n",
    "        # I fattori sono la differenza tra la media dei paesi \"above\" e \"below\" \n",
    "        avg_above_pc1 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in above_pc1]) if above_pc1 else 0\n",
    "        avg_below_pc1 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in below_pc1]) if below_pc1 else 0\n",
    "        PC1_factors[year][quarter] = avg_above_pc1 - avg_below_pc1\n",
    "\n",
    "        avg_above_pc2 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in above_pc2]) if above_pc2 else 0\n",
    "        avg_below_pc2 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in below_pc2]) if below_pc2 else 0\n",
    "        PC2_factors[year][quarter] = avg_above_pc2 - avg_below_pc2\n",
    "\n",
    "        avg_above_pc3 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in above_pc3]) if above_pc3 else 0\n",
    "        avg_below_pc3 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in below_pc3]) if below_pc3 else 0\n",
    "        PC3_factors[year][quarter] = avg_above_pc3 - avg_below_pc3\n",
    "\n",
    "        avg_above_pc4 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in above_pc4]) if above_pc4 else 0\n",
    "        avg_below_pc4 = np.mean([media_alpha[country][f'anno_{year}'][quarter] for country in below_pc4]) if below_pc4 else 0\n",
    "        PC4_factors[year][quarter] = avg_above_pc4 - avg_below_pc4\n",
    "\n",
    "\n",
    "# Stampa delle statistiche\n",
    "print(\"Above Median Counts:\")\n",
    "for variable, counts in above_counts.items():\n",
    "    print(f\"{variable}: {counts}\")\n",
    "\n",
    "print(\"\\nBelow Median Counts:\")\n",
    "for variable, counts in below_counts.items():\n",
    "    print(f\"{variable}: {counts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21375b3c-c4de-48d6-869c-9991e02a5015",
   "metadata": {},
   "source": [
    "# Modello MM4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af358f8e-c9e4-417e-9c26-467487cd1d75",
   "metadata": {},
   "source": [
    "Si iniziaizza il dataframe che conterrÃ  variabile dipendente e fattori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbfd13-f31d-44b4-a143-30886e3adbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77508e5-7c58-48d0-95ad-403db2d8f786",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Regressioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9852b49-6cd5-4ddf-8c1e-4806231ec6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = {}\n",
    "\n",
    "paesi = ['Germania', 'Francia', 'Italia', 'Spagna', 'Finlandia', 'Olanda']\n",
    "\n",
    "for paese in paesi:\n",
    "    data_frames[paese] = {} \n",
    "    categorie = [f'{paese}_a_SizeBM', f'{paese}_a_SizeEbit', f'{paese}_a_SizeINV']\n",
    "    \n",
    "    # Per ogni categoria (es. SizeBM)\n",
    "    for categoria in categorie:\n",
    "        categoria_base = categoria.split('_')[-1]\n",
    "        \n",
    "        # Per ogni portafoglio.\n",
    "        for i in range(1, 10):\n",
    "            portafoglio_key = f'{categoria_base}_portafoglio_{i}'\n",
    "            \n",
    "            y = []\n",
    "            PC1 = []\n",
    "            PC2 = []\n",
    "            PC3 = []\n",
    "            PC4 = []\n",
    "\n",
    "            # Per ogni anno e trimestre:\n",
    "            for anno, trimestri in alpha[categoria].items():\n",
    "                for trimestre, portafogli in trimestri.items():\n",
    "                    # estrai il valore alpha per il portafoglio attuale e aggiungilo alla serie y\n",
    "                    y.append(portafogli[f'Portafoglio_{i}'])\n",
    "                    \n",
    "                    PC1.append(PC1_factors[int(anno.split('_')[1])][trimestre])\n",
    "                    PC2.append(PC2_factors[int(anno.split('_')[1])][trimestre])\n",
    "                    PC3.append(PC3_factors[int(anno.split('_')[1])][trimestre])\n",
    "                    PC4.append(PC4_factors[int(anno.split('_')[1])][trimestre])\n",
    "            \n",
    "            # Aggiungi la serie y e i regressori al dizionario data_frames\n",
    "            data_frames[paese][portafoglio_key] = {\n",
    "                'y': y,\n",
    "                'PC1_factors': PC1,\n",
    "                'PC2_factors': PC2,\n",
    "                'PC3_factors': PC3,\n",
    "                'PC4_factors': PC4,\n",
    "\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8668c4c-0c8f-4d86-919a-9e165c24624d",
   "metadata": {},
   "source": [
    "Di seguito il codice per eseguire una regressione per ogni portafoglio scegliendo sulla base dei vari test quale modello utilizzare (vedere tesi). Si salvano i risultati e si printano le statistiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02abdd21-01fb-45c0-adcd-b9799d0703e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario per memorizzare i risultati di ogni regressione per ciascun paese\n",
    "regression_results = {}\n",
    "\n",
    "# Contatori per le statistiche\n",
    "total_regressions_saved = 0\n",
    "non_normal_residuals_count = 0\n",
    "heteroschedastic_residuals_count = 0\n",
    "ols_count = 0\n",
    "ols_hc3_count = 0\n",
    "rlm_count = 0\n",
    "\n",
    "# Contatori per significativitÃ \n",
    "ols_significant_count = 0\n",
    "ols_hc3_significant_count = 0\n",
    "rlm_significant_count = 0\n",
    "\n",
    "# Contatori per multicollinearitÃ \n",
    "multicollinearity_count = 0\n",
    "\n",
    "# Liste per accumulare gli R^2\n",
    "ols_r_squared_values = []\n",
    "ols_hc3_r_squared_values = []\n",
    "rlm_pseudo_r_squared_values = []\n",
    "\n",
    "# Per ogni paese\n",
    "for paese in paesi:\n",
    "    regression_results[paese] = {}  \n",
    "    categorie = ['SizeBM', 'SizeEbit', 'SizeINV']\n",
    "    \n",
    "    # Per ogni categoria\n",
    "    for categoria in categorie:\n",
    "        # Per ogni portafoglio\n",
    "        for i in range(1, 10):\n",
    "            portafoglio_key = f'{categoria}_portafoglio_{i}'\n",
    "            \n",
    "            y = pd.Series(data_frames[paese][portafoglio_key]['y'])\n",
    "            x1 = pd.Series(data_frames[paese][portafoglio_key]['PC1_factors'])\n",
    "            x2 = pd.Series(data_frames[paese][portafoglio_key]['PC2_factors'])\n",
    "            x3 = pd.Series(data_frames[paese][portafoglio_key]['PC3_factors'])\n",
    "            x4 = pd.Series(data_frames[paese][portafoglio_key]['PC4_factors'])\n",
    "\n",
    "            X_poly = pd.DataFrame({\n",
    "                'PC1': x1,\n",
    "                'PC2': x2,\n",
    "                'PC3': x3,\n",
    "                'PC4': x4\n",
    "            })\n",
    "\n",
    "            # Aggiungo l'intercetta\n",
    "            X_poly = sm.add_constant(X_poly)\n",
    "\n",
    "            # Calcolo VIF per ogni regressore\n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"Variable\"] = X_poly.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_poly.values, i) for i in range(X_poly.shape[1])]\n",
    "\n",
    "            # Se c'Ã¨ multicollinearitÃ  (VIF > 10), incremento il contatore\n",
    "            if (vif_data[\"VIF\"] > 10).any():\n",
    "                multicollinearity_count += 1\n",
    "                print(f\"MulticollinearitÃ  rilevata in {paese} per {portafoglio_key} (VIF > 10)\")\n",
    "            \n",
    "            # Esegui la regressione OLS\n",
    "            ols_model = sm.OLS(y, X_poly).fit()\n",
    "            \n",
    "            # Test di Jarque-Bera per la normalitÃ  dei residui\n",
    "            jb_test = jarque_bera(ols_model.resid)\n",
    "            jb_pvalue = jb_test[1] \n",
    "\n",
    "            is_significant = False  \n",
    "\n",
    "            if jb_pvalue < 0.05:                # Se non normalitÃ  uso RLM\n",
    "                non_normal_residuals_count += 1\n",
    "\n",
    "                rlm_model = sm.RLM(y, X_poly).fit()\n",
    "                rlm_count += 1\n",
    "                total_regressions_saved += 1\n",
    "\n",
    "                ss_total = np.sum((y - np.mean(y))**2)  \n",
    "                ss_resid = np.sum(rlm_model.resid**2)\n",
    "                pseudo_r_squared = 1 - (ss_resid / ss_total)\n",
    "                \n",
    "\n",
    "                # Controlla la significativitÃ  del modello RLM (basato sui p-value dei coefficienti)\n",
    "                if rlm_model.pvalues.iloc[1:].min() < 0.05:  \n",
    "                    rlm_significant_count += 1\n",
    "                    is_significant = True\n",
    "                coefficients = pd.Series(rlm_model.params, index=X_poly.columns)\n",
    "                pvalues = pd.Series(rlm_model.pvalues, index=X_poly.columns)\n",
    "                \n",
    "                regression_results[paese][portafoglio_key] = {\n",
    "                    'coefficients': coefficients,\n",
    "                    'pvalues': pvalues,\n",
    "                    'r_squared': pseudo_r_squared,\n",
    "                    'is_significant': is_significant\n",
    "                }\n",
    "            else:\n",
    "                # Test di White per eteroschedasticitÃ \n",
    "                white_test = het_white(ols_model.resid, ols_model.model.exog)\n",
    "                white_pvalue = white_test[1]\n",
    "\n",
    "                if white_pvalue < 0.05:                 # Se c'Ã¨ eteroschedasticitÃ  uso OLS HC3\n",
    "                    heteroschedastic_residuals_count += 1\n",
    "\n",
    "                    ols_hc3_model = ols_model.get_robustcov_results(cov_type='HC3')\n",
    "                    ols_hc3_count += 1\n",
    "                    total_regressions_saved += 1\n",
    "\n",
    "                    ols_hc3_r_squared_values.append(ols_hc3_model.rsquared)\n",
    "\n",
    "                    # Controlla la significativitÃ  del modello OLS HC3 (F-statistic)\n",
    "                    if ols_hc3_model.f_pvalue < 0.05:  \n",
    "                        ols_hc3_significant_count += 1\n",
    "                        is_significant = True\n",
    "\n",
    "                    coefficients = pd.Series(ols_hc3_model.params, index=X_poly.columns)\n",
    "                    pvalues = pd.Series(ols_hc3_model.pvalues, index=X_poly.columns)\n",
    "\n",
    "                    regression_results[paese][portafoglio_key] = {\n",
    "                        'coefficients': coefficients,#ols_hc3_model.params,\n",
    "                        'pvalues': pvalues,#ols_hc3_model.pvalues,\n",
    "                        'r_squared': ols_hc3_model.rsquared,\n",
    "                        'is_significant': is_significant\n",
    "                    }\n",
    "                else:\n",
    "                    # Usa OLS standard\n",
    "                    ols_count += 1\n",
    "                    total_regressions_saved += 1\n",
    "\n",
    "                    ols_r_squared_values.append(ols_model.rsquared)\n",
    "\n",
    "                    # Controlla la significativitÃ  del modello OLS standard (F-statistic)\n",
    "                    if ols_model.f_pvalue < 0.05: \n",
    "                        ols_significant_count += 1\n",
    "                        is_significant = True\n",
    "\n",
    "                    regression_results[paese][portafoglio_key] = {\n",
    "                        'coefficients': ols_model.params,\n",
    "                        'pvalues': ols_model.pvalues,\n",
    "                        'r_squared': ols_model.rsquared,\n",
    "                        'is_significant': is_significant\n",
    "                    }\n",
    "\n",
    "# Calcola gli R^2 medi\n",
    "ols_r_squared_mean = np.mean(ols_r_squared_values) if ols_r_squared_values else np.nan\n",
    "ols_hc3_r_squared_mean = np.mean(ols_hc3_r_squared_values) if ols_hc3_r_squared_values else np.nan\n",
    "rlm_pseudo_r_squared_mean = np.mean(rlm_pseudo_r_squared_values) if rlm_pseudo_r_squared_values else np.nan\n",
    "\n",
    "# Stampa del riepilogo\n",
    "print(f\"Totale regressioni salvate: {total_regressions_saved}\")\n",
    "print(f\"Totale regressioni con residui non normali (Jarque-Bera): {non_normal_residuals_count}\")\n",
    "print(f\"Totale regressioni con residui eteroschedastici (White test): {heteroschedastic_residuals_count}\")\n",
    "print(f\"Regressioni eseguite con OLS: {ols_count}\")\n",
    "print(f\"Regressioni eseguite con OLS HC3: {ols_hc3_count}\")\n",
    "print(f\"Regressioni eseguite con RLM: {rlm_count}\")\n",
    "print(f\"Regressioni OLS significative (F-statistic < 0.05): {ols_significant_count}\")\n",
    "print(f\"Regressioni OLS HC3 significative (F-statistic < 0.05): {ols_hc3_significant_count}\")\n",
    "print(f\"Regressioni RLM significative (coefficients p-value < 0.05): {rlm_significant_count}\")\n",
    "\n",
    "print(\"\\n--- RÂ² Medi ---\")\n",
    "print(f\"RÂ² medio per OLS: {ols_r_squared_mean:.4f}\" if not np.isnan(ols_r_squared_mean) else \"Nessun RÂ² calcolato per OLS.\")\n",
    "print(f\"RÂ² medio per OLS HC3: {ols_hc3_r_squared_mean:.4f}\" if not np.isnan(ols_hc3_r_squared_mean) else \"Nessun RÂ² calcolato per OLS HC3.\")\n",
    "print(f\"Pseudo RÂ² medio per RLM: {rlm_pseudo_r_squared_mean:.4f}\" if not np.isnan(rlm_pseudo_r_squared_mean) else \"Nessun pseudo RÂ² calcolato per RLM.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f6063-f170-4f2a-ab8f-5aff4e6fe930",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analisi R quadri (Facoltativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c73f2-0a62-4867-9a93-18242a37b02a",
   "metadata": {},
   "source": [
    "Visualizzazione degli R quadri e pseudo R quadri medi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af85e4-21e5-4895-af62-e997438102c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare gli R^2 aggiustati e creare heatmap\n",
    "def calcola_e_visualizza_r2_adj(regression_results, tipo_size, paesi):\n",
    "    r2_adj_data = {f'Portafoglio_{i}': [] for i in range(1, 10)}\n",
    "\n",
    "    for paese in paesi:\n",
    "        for i in range(1, 10):\n",
    "            portafoglio_key = f'{tipo_size}_portafoglio_{i}'\n",
    "\n",
    "            if paese in regression_results and portafoglio_key in regression_results[paese]:\n",
    "                r2 = regression_results[paese][portafoglio_key].get('r_squared', None)\n",
    "\n",
    "                # Se il valore di r2_adj Ã¨ valido (non None), aggiungilo alla lista\n",
    "                if r2 is not None:\n",
    "                    r2_data[f'Portafoglio_{i}'].append(r2)\n",
    "                else:\n",
    "                    r2_data[f'Portafoglio_{i}'].append(None)  # Aggiungi None se 'r_squared' Ã¨ mancante\n",
    "            else:\n",
    "                r2_data[f'Portafoglio_{i}'].append(None)\n",
    "\n",
    "    # Crea il DataFrame con l'indice dei Paesi e le colonne per i portafogli\n",
    "    r2_df = pd.DataFrame(r2_data, index=paesi)\n",
    "\n",
    "    r2_df.loc['Media'] = r2_df.mean()\n",
    "\n",
    "    r2_df['Media'] = r2_df.mean(axis=1)\n",
    "\n",
    "    # Converti i valori dell'R^2 aggiustato in percentuale\n",
    "    r2_df_percentage = r2_df * 100 \n",
    "\n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    sns.heatmap(r2_df_percentage, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", cbar_kws={'label': 'R^2 Aggiustato (%)'})\n",
    "    plt.title(f\"R^2 Aggiustato (%) per ciascun portafoglio {tipo_size} e paese\")\n",
    "    plt.xlabel(f\"Portafogli {tipo_size}\")\n",
    "    plt.ylabel(\"Paesi\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "calcola_e_visualizza_r2_adj(regression_results, 'SizeBM', paesi)\n",
    "calcola_e_visualizza_r2_adj(regression_results, 'SizeEbit', paesi)\n",
    "calcola_e_visualizza_r2_adj(regression_results, 'SizeINV', paesi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b19a8-a7e9-4c5e-bad2-327cddf0104d",
   "metadata": {},
   "source": [
    "Calcolo degli R quadri medi per ogni categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5437be-56a3-41e6-98f7-ef8713b8feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "paesi = ['Germania','Francia','Italia','Spagna', 'Finlandia','Olanda']\n",
    "categorie = ['SizeBM', 'SizeEbit', 'SizeINV']\n",
    "\n",
    "r_quadro_small = []\n",
    "r_quadro_mid = []\n",
    "r_quadro_big = []\n",
    "\n",
    "small_all = []\n",
    "mid_all = []\n",
    "big_all = []\n",
    "\n",
    "for paese in paesi:\n",
    "    small = []\n",
    "    mid = []\n",
    "    big = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9]:\n",
    "        if i in [1,2,3]:\n",
    "            for categoria in categorie:\n",
    "                x = regression_results[paese][f'{categoria}_portafoglio_{i}']['r_squared']\n",
    "                small.append(x)\n",
    "                small_all.append(x)\n",
    "                \n",
    "        if i in [4,5,6]:\n",
    "            for categoria in categorie:\n",
    "                x = regression_results[paese][f'{categoria}_portafoglio_{i}']['r_squared']\n",
    "                mid.append(x)\n",
    "                mid_all.append(x)\n",
    "\n",
    "        if i in [7,8,9]:\n",
    "            for categoria in categorie:\n",
    "                x = regression_results[paese][f'{categoria}_portafoglio_{i}']['r_squared']\n",
    "                big.append(x)\n",
    "                big_all.append(x)\n",
    "                \n",
    "    media_small = statistics.mean(small)\n",
    "    media_mid = statistics.mean(mid)\n",
    "    media_big = statistics.mean(big)\n",
    "\n",
    "    r_quadro_small.append(media_small)\n",
    "    r_quadro_mid.append(media_mid)\n",
    "    r_quadro_big.append(media_big)\n",
    "\n",
    "print('R quadro medio delle small per ogni paese:', len(r_quadro_small))\n",
    "print('R quadro medio delle mid per ogni paese:', len(r_quadro_mid))\n",
    "print('R quadro medio delle big per ogni paese:', len(r_quadro_big))\n",
    "\n",
    "r_quadro_low = []\n",
    "r_quadro_mean = []\n",
    "r_quadro_high = []\n",
    "\n",
    "low_all = []\n",
    "mean_all = []\n",
    "high_all = []\n",
    "\n",
    "for paese in paesi:\n",
    "    low = []\n",
    "    mean = []\n",
    "    high = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9]:\n",
    "        if i in [1,4,7]:\n",
    "            x = regression_results[paese][f'SizeBM_portafoglio_{i}']['r_squared']\n",
    "            low.append(x)\n",
    "            low_all.append(x)\n",
    "        elif i in [2,5,8]:\n",
    "            x = regression_results[paese][f'SizeBM_portafoglio_{i}']['r_squared']\n",
    "            mean.append(x)\n",
    "            mean_all.append(x)\n",
    "        else:\n",
    "            x = regression_results[paese][f'SizeBM_portafoglio_{i}']['r_squared']\n",
    "            high.append(x)\n",
    "            high_all.append(x)\n",
    "\n",
    "    media_low = statistics.mean(low)\n",
    "    media_mean = statistics.mean(mean)\n",
    "    media_high = statistics.mean(high)\n",
    "\n",
    "    r_quadro_low.append(media_low)\n",
    "    r_quadro_mean.append(media_mean)\n",
    "    r_quadro_high.append(media_high)\n",
    "\n",
    "print('R quadro medio delle low per ogni paese:', len(r_quadro_low))\n",
    "print('R quadro medio delle mean per ogni paese:', len(r_quadro_mean))\n",
    "print('R quadro medio delle high per ogni paese:', len(r_quadro_high))\n",
    "\n",
    "r_quadro_weak = []\n",
    "r_quadro_mean1 = []\n",
    "r_quadro_rob = []\n",
    "\n",
    "weak_all = []\n",
    "mean1_all = []\n",
    "rob_all = []\n",
    "\n",
    "for paese in paesi:\n",
    "    weak = []\n",
    "    mean1 = []\n",
    "    rob = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9]:\n",
    "        if i in [1,4,7]:\n",
    "            x = regression_results[paese][f'SizeEbit_portafoglio_{i}']['r_squared']\n",
    "            weak.append(x)\n",
    "            weak_all.append(x)\n",
    "        if i in [2,5,8]:\n",
    "            x = regression_results[paese][f'SizeEbit_portafoglio_{i}']['r_squared']\n",
    "            mean1.append(x)\n",
    "            mean1_all.append(x)\n",
    "        if i in [3,6,9]:\n",
    "            x = regression_results[paese][f'SizeEbit_portafoglio_{i}']['r_squared']\n",
    "            rob.append(x)\n",
    "            rob_all.append(x)\n",
    "\n",
    "    media_weak = statistics.mean(weak)\n",
    "    media_mean1 = statistics.mean(mean1)\n",
    "    media_rob = statistics.mean(rob)\n",
    "\n",
    "    r_quadro_weak.append(media_weak)\n",
    "    r_quadro_mean1.append(media_mean1)\n",
    "    r_quadro_rob.append(media_rob)\n",
    "\n",
    "print('R quadro medio delle low per ogni paese:', len(r_quadro_weak))\n",
    "print('R quadro medio delle mean per ogni paese:', len(r_quadro_mean1))\n",
    "print('R quadro medio delle high per ogni paese:', len(r_quadro_rob))\n",
    "\n",
    "r_quadro_cons = []\n",
    "r_quadro_mean2 = []\n",
    "r_quadro_aggr = []\n",
    "\n",
    "cons_all = []\n",
    "mean2_all = []\n",
    "aggr_all = []\n",
    "\n",
    "for paese in paesi:\n",
    "    cons = []\n",
    "    mean2 = []\n",
    "    aggr = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9]:\n",
    "        if i in [1,4,7]:\n",
    "            x = regression_results[paese][f'SizeINV_portafoglio_{i}']['r_squared']\n",
    "            cons.append(x)\n",
    "            cons_all.append(x)\n",
    "        if i in [2,5,8]:\n",
    "            x = regression_results[paese][f'SizeINV_portafoglio_{i}']['r_squared']\n",
    "            mean2.append(x)\n",
    "            mean2_all.append(x)\n",
    "        if i in [3,6,9]:\n",
    "            x = regression_results[paese][f'SizeINV_portafoglio_{i}']['r_squared']\n",
    "            aggr.append(x)\n",
    "            aggr_all.append(x)\n",
    "\n",
    "    media_cons = statistics.mean(cons)\n",
    "    media_mean2 = statistics.mean(mean2)\n",
    "    media_aggr = statistics.mean(aggr)\n",
    "\n",
    "    r_quadro_cons.append(media_cons)\n",
    "    r_quadro_mean2.append(media_mean2)\n",
    "    r_quadro_aggr.append(media_aggr)\n",
    "\n",
    "print('R quadro medio delle low per ogni paese:', len(r_quadro_cons))\n",
    "print('R quadro medio delle mean per ogni paese:', len(r_quadro_mean2))\n",
    "print('R quadro medio delle high per ogni paese:', len(r_quadro_aggr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f8a8e-d65f-4b3a-ac5a-44d4a5f8bf53",
   "metadata": {},
   "source": [
    "Preparazione del Dataset per la creazione di grafici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8446625-9a22-42ad-b6d9-968119b05347",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = ['Small Cap', 'Mid Cap', 'Big Cap', 'Small Cap', 'Mid Cap', 'Big Cap', 'Small Cap', 'Mid Cap', 'Big Cap',\n",
    "        'Small Cap', 'Mid Cap', 'Big Cap', 'Small Cap', 'Mid Cap', 'Big Cap', 'Small Cap', 'Mid Cap', 'Big Cap',]\n",
    "\n",
    "Nazione = ['Germania', 'Germania', 'Germania', 'Francia', 'Francia', 'Francia', 'Italia', 'Italia', 'Italia',\n",
    "           'Spagna', 'Spagna', 'Spagna', 'Finlandia', 'Finlandia', 'Finlandia', 'Olanda', 'Olanda', 'Olanda']\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'Small': small_all,\n",
    "    'Mid': mid_all,\n",
    "    'Big': big_all\n",
    "})\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Category': sizes, \n",
    "    'Low': low_all,\n",
    "    #'Mean': mean_all,\n",
    "    'High': high_all\n",
    "})\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'Category': sizes, \n",
    "    'Weak': weak_all,\n",
    "    #'Mean': mean1_all,\n",
    "    'Robust': rob_all\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Category': sizes, \n",
    "    'Conservative': cons_all,\n",
    "    #'Mean': mean2_all,\n",
    "    'Aggressive': aggr_all\n",
    "})\n",
    "df = df[~df.isin(['Mid Cap']).any(axis=1)]\n",
    "df1 = df1[~df1.isin(['Mid Cap']).any(axis=1)]\n",
    "df2 = df2[~df2.isin(['Mid Cap']).any(axis=1)]\n",
    "df_melted = df4.melt(value_vars=[\"Small\",\"Mid\", \"Big\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d14b9-063a-4e64-8c76-7a226d408430",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "df_melted = df4.melt(value_vars=[\"Small\",\"Mid\", \"Big\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(y='Value', hue='Type', data=df_melted, inner=\"quart\", \n",
    "               palette=\"muted\", ax=axes[0], alpha=0.75)\n",
    "axes[0].set_title('Violin Plot per Small, Mid e Big Cap')\n",
    "axes[0].set_ylabel('Valore')\n",
    "\n",
    "df_melted = df.melt(id_vars=[\"Category\"], value_vars=[\"Low\", \"High\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(x='Category', y='Value', hue='Type', data=df_melted, \n",
    "               inner=\"quart\", palette=\"muted\", split=True, ax=axes[1], alpha=0.75)\n",
    "axes[1].set_title('Violin Plot per Low, Mean e High')\n",
    "axes[1].set_ylabel('Valore')\n",
    "\n",
    "df_melted = df1.melt(id_vars=[\"Category\"], value_vars=[\"Weak\",\"Robust\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(x='Category', y='Value', hue='Type', data=df_melted, \n",
    "               inner=\"quart\", palette=\"muted\", split=True, ax=axes[2], alpha=0.75)\n",
    "axes[2].set_title('Violin Plot per Weak, Mean e Robust')\n",
    "axes[2].set_ylabel('Valore')\n",
    "\n",
    "df_melted = df2.melt(id_vars=[\"Category\"], value_vars=[\"Conservative\", \"Aggressive\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(x='Category', y='Value', hue='Type', data=df_melted, \n",
    "               inner=\"quart\", palette=\"muted\", split=True, ax=axes[3], alpha=0.75)\n",
    "axes[3].set_title('Violin Plot per Cons, Mean e Aggr')\n",
    "axes[3].set_ylabel('Valore')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738de0e4-a2a9-4688-8820-af11d49d567c",
   "metadata": {},
   "source": [
    "Test di Kruskal-Wallis per testare la differenza tra i gruppi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a99b1-3bfa-411a-8bf0-2e6429731a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differenza tra Small e Big\n",
    "stat, p_value_kw = stats.kruskal(small_all, big_all)\n",
    "\n",
    "print(f\"Test di Kruskal-Wallis statistic: {stat:.2f}\")\n",
    "print(f\"P-value: {p_value_kw:.4f}\")\n",
    "\n",
    "if p_value_kw < 0.05:\n",
    "    print(\"Le medie tra i gruppi sono significativamente diverse (p < 0.05).\")\n",
    "else:\n",
    "    print(\"Le medie tra i gruppi non sono significativamente diverse (p >= 0.05).\")\n",
    "\n",
    "# Differenza tra Low e High\n",
    "f_stat, p_value = stats.kruskal(low_all,  high_all)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Le medie sono significativamente diverse tra loro (p < 0.05).\")\n",
    "else:\n",
    "    print(\"Le medie non sono significativamente diverse tra loro (p >= 0.05).\")\n",
    "\n",
    "# Differenza tra Weak e Robust\n",
    "f_stat, p_value = stats.kruskal(weak_all,  rob_all)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Le medie sono significativamente diverse tra loro (p < 0.05).\")\n",
    "else:\n",
    "    print(\"Le medie non sono significativamente diverse tra loro (p >= 0.05).\")\n",
    "\n",
    "# Differenza tra Conservative e Aggressive\n",
    "f_stat, p_value = stats.kruskal(cons_all, aggr_all)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Le medie sono significativamente diverse tra loro (p < 0.05).\")\n",
    "else:\n",
    "    print(\"Le medie non sono significativamente diverse tra loro (p >= 0.05).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86dd54-2987-44ab-867a-612be1562e45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analisi dei Coefficienti (facoltativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c1f7f-e50f-45a9-a140-8422c74b3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficiente = 4\n",
    "\n",
    "coeff_1_small = []\n",
    "coeff_2_small = []\n",
    "coeff_3_small = []\n",
    "coeff_4_small = []\n",
    "coeff_1_mid = []\n",
    "coeff_2_mid = []\n",
    "coeff_3_mid = []\n",
    "coeff_4_mid = []\n",
    "coeff_1_big = []\n",
    "coeff_2_big = []\n",
    "coeff_3_big = []\n",
    "coeff_4_big = []\n",
    "\n",
    "small_coeff_1 = []\n",
    "mid_coeff_1 = []\n",
    "big_coeff_1 = []\n",
    "small_coeff_2 = []\n",
    "mid_coeff_2 = []\n",
    "big_coeff_2 = []\n",
    "small_coeff_3 = []\n",
    "mid_coeff_3 = []\n",
    "big_coeff_3 = []\n",
    "small_coeff_4 = []\n",
    "mid_coeff_4 = []\n",
    "big_coeff_4 = []\n",
    "\n",
    "for paese in paesi:\n",
    "    small_1 = []\n",
    "    small_2 = []\n",
    "    small_3 = []\n",
    "    small_4 = []\n",
    "    mid_1 = []\n",
    "    mid_2 = []\n",
    "    mid_3 = []\n",
    "    mid_4 = []\n",
    "    big_1 = []\n",
    "    big_2 = []\n",
    "    big_3 = []\n",
    "    big_4 = []\n",
    "    for i in [1,2,3,4,5,6,7,8,9]:\n",
    "        if i in [1,2,3]:\n",
    "            for categoria in categorie:\n",
    "                for n in [1,2,3,4]:\n",
    "                    x = regression_results[paese][f'{categoria}_portafoglio_{i}']['coefficients'][n]\n",
    "                    if n == 1:\n",
    "                        small_1.append(x)\n",
    "                        small_coeff_1.append(x)\n",
    "                    elif n == 2:\n",
    "                        small_2.append(x)\n",
    "                        small_coeff_2.append(x)\n",
    "                    elif n == 3:\n",
    "                        small_3.append(x)\n",
    "                        small_coeff_3.append(x)\n",
    "                    else:\n",
    "                        small_4.append(x)\n",
    "                        small_coeff_4.append(x)\n",
    "                \n",
    "        if i in [4,5,6]:\n",
    "            for categoria in categorie:\n",
    "                for n in [1,2,3,4]:\n",
    "                    x = regression_results[paese][f'{categoria}_portafoglio_{i}']['coefficients'][n]\n",
    "                    if n == 1:\n",
    "                        mid_1.append(x)\n",
    "                        mid_coeff_1.append(x)\n",
    "                    elif n == 2:\n",
    "                        mid_2.append(x)\n",
    "                        mid_coeff_2.append(x)\n",
    "                    elif n == 3:\n",
    "                        mid_3.append(x)\n",
    "                        mid_coeff_3.append(x)\n",
    "                    else:\n",
    "                        mid_4.append(x)\n",
    "                        mid_coeff_4.append(x)\n",
    "        if i in [7,8,9]:\n",
    "            for categoria in categorie:\n",
    "                for n in [1,2,3,4]:\n",
    "                    x = regression_results[paese][f'{categoria}_portafoglio_{i}']['coefficients'][n]\n",
    "                    if n == 1:\n",
    "                        big_1.append(x)\n",
    "                        big_coeff_1.append(x)\n",
    "                    elif n == 2:\n",
    "                        big_2.append(x)\n",
    "                        big_coeff_2.append(x)\n",
    "                    elif n == 3:\n",
    "                        big_3.append(x)\n",
    "                        big_coeff_3.append(x)\n",
    "                    else:\n",
    "                        big_4.append(x)\n",
    "                        big_coeff_4.append(x)\n",
    "                \n",
    "    media_small_1 = statistics.mean(small_1)\n",
    "    media_small_2 = statistics.mean(small_2)\n",
    "    media_small_3 = statistics.mean(small_3)\n",
    "    media_small_4 = statistics.mean(small_4)\n",
    "    media_mid_1 = statistics.mean(mid_1)\n",
    "    media_mid_2 = statistics.mean(mid_2)\n",
    "    media_mid_3 = statistics.mean(mid_3)\n",
    "    media_mid_4 = statistics.mean(mid_4)\n",
    "    media_big_1 = statistics.mean(big_1)\n",
    "    media_big_2 = statistics.mean(big_2)\n",
    "    media_big_3 = statistics.mean(big_3)\n",
    "    media_big_4 = statistics.mean(big_4)\n",
    "\n",
    "    coeff_1_small.append(media_small_1)\n",
    "    coeff_2_small.append(media_small_2)\n",
    "    coeff_3_small.append(media_small_3)\n",
    "    coeff_4_small.append(media_small_4)\n",
    "    coeff_1_mid.append(media_mid_1)\n",
    "    coeff_2_mid.append(media_mid_2)\n",
    "    coeff_3_mid.append(media_mid_3)\n",
    "    coeff_4_mid.append(media_mid_4)\n",
    "    coeff_1_big.append(media_big_1)\n",
    "    coeff_2_big.append(media_big_2)\n",
    "    coeff_3_big.append(media_big_3)\n",
    "    coeff_4_big.append(media_big_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de5eeb-f2e7-4347-a5aa-5096364ceced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Small': coeff_1_small,\n",
    "    'Mid': coeff_1_mid,\n",
    "    'Big': coeff_1_big\n",
    "})\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'Small': coeff_2_small,\n",
    "    'Mid': coeff_2_mid,\n",
    "    'Big': coeff_2_big\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Small': coeff_3_small,\n",
    "    'Mid': coeff_3_mid,\n",
    "    'Big': coeff_3_big\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'Small': coeff_4_small,\n",
    "    'Mid': coeff_4_mid,\n",
    "    'Big': coeff_4_big\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3df70-55bf-4816-b503-a6395ec38098",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "all_values = pd.concat([df.melt(value_vars=[\"Small\", \"Mid\", \"Big\"])['value'],\n",
    "                        df1.melt(value_vars=[\"Small\", \"Mid\", \"Big\"])['value'],\n",
    "                        df2.melt(value_vars=[\"Small\", \"Mid\", \"Big\"])['value'],\n",
    "                        df3.melt(value_vars=[\"Small\", \"Mid\", \"Big\"])['value']])\n",
    "y_min, y_max = all_values.min(), all_values.max()\n",
    "margin = (y_max - y_min) * 0.25  \n",
    "y_min, y_max = y_min - margin, y_max + margin\n",
    "\n",
    "df_melted = df.melt(value_vars=[\"Small\", \"Mid\", \"Big\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(y='Value', hue='Type', data=df_melted, inner=\"quart\", \n",
    "               palette=\"muted\", ax=axes[0], alpha=0.75)\n",
    "axes[0].set_title('Fattore 1 per Small, Mid e Big Cap')\n",
    "axes[0].set_ylabel('Valore')\n",
    "axes[0].set_ylim(y_min, y_max)  \n",
    "\n",
    "df_melted = df1.melt(value_vars=[\"Small\", \"Mid\", \"Big\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(y='Value', hue='Type', data=df_melted, inner=\"quart\", \n",
    "               palette=\"muted\", ax=axes[1], alpha=0.75)\n",
    "axes[1].set_title('Fattore 2 per Small, Mid e Big Cap')\n",
    "axes[1].set_ylabel('Valore')\n",
    "axes[1].set_ylim(y_min, y_max)  \n",
    "\n",
    "df_melted = df2.melt(value_vars=[\"Small\", \"Mid\", \"Big\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(y='Value', hue='Type', data=df_melted, inner=\"quart\", \n",
    "               palette=\"muted\", ax=axes[2], alpha=0.75)\n",
    "axes[2].set_title('Fattore 3 per Small, Mid e Big Cap')\n",
    "axes[2].set_ylabel('Valore')\n",
    "axes[2].set_ylim(y_min, y_max) \n",
    "\n",
    "df_melted = df3.melt(value_vars=[\"Small\", \"Mid\", \"Big\"], \n",
    "                    var_name=\"Type\", value_name=\"Value\")\n",
    "\n",
    "sns.violinplot(y='Value', hue='Type', data=df_melted, inner=\"quart\", \n",
    "               palette=\"muted\", ax=axes[3], alpha=0.75)\n",
    "axes[3].set_title('Fattore 4 per Small, Mid e Big Cap')\n",
    "axes[3].set_ylabel('Valore')\n",
    "axes[3].set_ylim(y_min, y_max)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381b6be-6cc0-4f80-9d6d-c5e003e77276",
   "metadata": {},
   "source": [
    "# Modello Fama Macbeth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050452c4-3d75-4cc5-9634-161ab66ad31c",
   "metadata": {},
   "source": [
    "Salvataggio dei coefficienti da regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adf74e-580d-452c-b848-968708b0951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario per memorizzare solo i coefficienti\n",
    "coefficients_results = {}\n",
    "\n",
    "for paese in paesi:\n",
    "    coefficients_results[paese] = {}\n",
    "    \n",
    "    for categoria in categorie:\n",
    "        for i in range(1, 10):\n",
    "            portafoglio_key = f'{categoria}_portafoglio_{i}'\n",
    "            \n",
    "            coefficients_results[paese][portafoglio_key] = regression_results[paese][portafoglio_key]['coefficients']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b5b8c-3071-435b-9d0e-00f6e20188c3",
   "metadata": {},
   "source": [
    "## Regressioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68071464-93fd-4750-930c-11265f21fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario per memorizzare i risultati delle regressioni Fama-MacBeth\n",
    "fama_macbeth_results = {}\n",
    "\n",
    "ols_significant = 0\n",
    "ols_hc3_significant = 0\n",
    "rlm_significant = 0\n",
    "\n",
    "paesi = ['Germania', 'Francia', 'Italia', 'Spagna', 'Finlandia', 'Olanda']\n",
    "categorie = ['SizeBM', 'SizeEbit', 'SizeINV']\n",
    "\n",
    "num_periodi = 80  \n",
    "\n",
    "# Per ogni trimestre\n",
    "for periodo in range(num_periodi):\n",
    "    y_values = []  \n",
    "    x_values = [] \n",
    "\n",
    "    # Per ogni paese\n",
    "    for paese in paesi:\n",
    "        # Per ogni categoria\n",
    "        for categoria in categorie:\n",
    "            # Per ogni portafoglio\n",
    "            for i in range(1, 10):  \n",
    "                y_value = data_frames[paese][f'{categoria}_portafoglio_{i}']['y'][periodo]\n",
    "                y_values.append(y_value)\n",
    "\n",
    "                coefficients = coefficients_results[paese][f'{categoria}_portafoglio_{i}']\n",
    "                x_values.append(coefficients[1:])  # Il primo coefficiente Ã¨ escluso (intercetta)\n",
    "\n",
    "    y_array = np.array(y_values)  # y diventa un array unidimensionale.\n",
    "    X = pd.DataFrame(x_values)  # X diventa un DataFrame.\n",
    "\n",
    "    if X.columns.duplicated().any():\n",
    "        print(f\"Attenzione: Colonne duplicate trovate per il periodo {periodo}. Controlla i dati.\")\n",
    "        continue\n",
    "\n",
    "    # Aggiungi un'intercetta a X\n",
    "    X = sm.add_constant(X)\n",
    "    is_significant = False  \n",
    "\n",
    "\n",
    "    # Esegui la regressione OLS \n",
    "    if len(y_array) == len(X):\n",
    "        ols_model = sm.OLS(y_array, X).fit()\n",
    "\n",
    "        # Test JB per la normalitÃ  dei residui.\n",
    "        jb_statistic, jb_pvalue, _, _ = jarque_bera(ols_model.resid)\n",
    "\n",
    "        # Se non normali eseguo RLM\n",
    "        if jb_pvalue < 0.05:\n",
    "            rlm_model = sm.RLM(y_array, X).fit()\n",
    "            if ss_total <= 0:\n",
    "                raise ValueError(\"La somma totale dei quadrati (SS_total) deve essere positiva.\")\n",
    "\n",
    "            rlm_predicted = rlm_model.predict(X)\n",
    "            ss_total = np.sum((y - np.mean(y))**2) \n",
    "            ss_resid = np.sum(rlm_model.resid**2)\n",
    "            if ss_total >= ss_resid:\n",
    "                print(\"ss_total maggiore di ss_resid.\")\n",
    "            pseudo_r_squared = max(-1, 1 - (ss_resid / ss_total))\n",
    "\n",
    "            # Controlla la significativitÃ  del modello RLM (basato sui p-value dei coefficienti)\n",
    "            if rlm_model.pvalues.iloc[1:].min() < 0.05:  \n",
    "                rlm_significant += 1\n",
    "                is_significant = True\n",
    "            \n",
    "            coefficients = pd.Series(rlm_model.params[1:], index=X.columns[1:])\n",
    "            pvalues = pd.Series(rlm_model.pvalues[1:], index=X.columns[1:])\n",
    "\n",
    "            fama_macbeth_results[f'periodo_{periodo}'] = {\n",
    "                'coefficients': coefficients,  \n",
    "                'pvalues': pvalues,      \n",
    "                'adj_r_squared': pseudo_r_squared,\n",
    "                'is_significant': is_significant,\n",
    "                'model_type': 'RLM'\n",
    "            }\n",
    "        else:\n",
    "            # Test di White per eteroschedasticitÃ \n",
    "            white_test = het_white(ols_model.resid, ols_model.model.exog)\n",
    "            white_pvalue = white_test[1]\n",
    "\n",
    "            if white_pvalue < 0.05:\n",
    "                # Se i residui sono eteroschedastici --> OLS HC3\n",
    "                ols_hc3_model = ols_model.get_robustcov_results(cov_type='HC3')\n",
    "                print(X.columns)\n",
    "                coefficients_series = pd.Series(ols_hc3_model.params[1:], index=X.columns[1:])\n",
    "                pvalues_series = pd.Series(ols_hc3_model.pvalues[1:], index=X.columns[1:])\n",
    "\n",
    "                if ols_hc3_model.f_pvalue < 0.05:  \n",
    "                    ols_hc3_significant += 1\n",
    "                    is_significant = True\n",
    "\n",
    "                fama_macbeth_results[f'periodo_{periodo}'] = {\n",
    "                    'coefficients': coefficients_series,  \n",
    "                    'pvalues': pvalues_series,            \n",
    "                    'adj_r_squared': ols_hc3_model.rsquared,\n",
    "                    'is_significant': is_significant,\n",
    "                    'model_type': 'OLS HC3'\n",
    "                }\n",
    "            else:\n",
    "                if ols_model.f_pvalue < 0.05:  \n",
    "                    ols_significant += 1\n",
    "                    is_significant = True\n",
    "                # Se i residui sono normali e omoschedastici salvo i risultati del modello OLS.\n",
    "                fama_macbeth_results[f'periodo_{periodo}'] = {\n",
    "                    'coefficients': ols_model.params[1:],   \n",
    "                    'pvalues': ols_model.pvalues[1:],       \n",
    "                    'adj_r_squared': ols_model.rsquared,\n",
    "                    'is_significant': is_significant,\n",
    "                    'model_type': 'OLS'\n",
    "                }\n",
    "\n",
    "\n",
    "# Visualizza i risultati delle regressioni Fama-MacBeth\n",
    "for key, result in fama_macbeth_results.items():\n",
    "    print(f\"{key}: Model Type: {result['model_type']}, Coefficients: {result['coefficients']}, \"\n",
    "          f\"P-values: {result['pvalues']}, Adjusted R-squared: {result['adj_r_squared']}\")\n",
    "\n",
    "\n",
    "# Calcolo statistiche\n",
    "ols_count = 0\n",
    "ols_hc3_count = 0\n",
    "rlm_count = 0\n",
    "\n",
    "ols_r_squared = []\n",
    "ols_hc3_r_squared = []\n",
    "rlm_pseudo_r_squared = []\n",
    "\n",
    "\n",
    "for result in fama_macbeth_results.values():\n",
    "    model_type = result['model_type']\n",
    "    adj_r_squared = result['adj_r_squared']\n",
    "    pvalues = result['pvalues']\n",
    "\n",
    "    if model_type == 'OLS':\n",
    "        ols_count += 1\n",
    "        ols_r_squared.append(adj_r_squared)\n",
    "    elif model_type == 'OLS HC3':\n",
    "        ols_hc3_count += 1\n",
    "        ols_hc3_r_squared.append(adj_r_squared)\n",
    "    elif model_type == 'RLM':\n",
    "        rlm_count += 1\n",
    "        rlm_pseudo_r_squared.append(adj_r_squared)\n",
    "\n",
    "# Calcolo le medie degli RÂ² e pseudo-RÂ²\n",
    "ols_avg_r_squared = sum(ols_r_squared) / len(ols_r_squared) if ols_r_squared else None\n",
    "ols_hc3_avg_r_squared = sum(ols_hc3_r_squared) / len(ols_hc3_r_squared) if ols_hc3_r_squared else None\n",
    "rlm_avg_pseudo_r_squared = sum(rlm_pseudo_r_squared) / len(rlm_pseudo_r_squared) if rlm_pseudo_r_squared else None\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model Type': ['OLS', 'OLS HC3', 'RLM'],\n",
    "    'Number of Regressions': [ols_count, ols_hc3_count, rlm_count],\n",
    "    'Average RÂ²': [ols_avg_r_squared, ols_hc3_avg_r_squared, None],\n",
    "    'Average Pseudo RÂ²': [None, None, rlm_avg_pseudo_r_squared],\n",
    "    'Number of Significant Models': [ols_significant, ols_hc3_significant, rlm_significant]\n",
    "})\n",
    "\n",
    "# Salva i risultati in un file Excel\n",
    "output_file = 'fama_macbeth_summary_SHOCK.xlsx'\n",
    "summary_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Risultati salvati in {output_file}\")\n",
    "\n",
    "\n",
    "# Lista per memorizzare i coefficienti di ogni variabile per ciascun periodo\n",
    "coefficients_by_variable = {}\n",
    "\n",
    "# Raccogli i coefficienti per ogni variabile attraverso i periodi\n",
    "for periodo, result in fama_macbeth_results.items():\n",
    "    coefficients = result['coefficients']\n",
    "    for idx, coeff in enumerate(coefficients):\n",
    "        if idx not in coefficients_by_variable:\n",
    "            coefficients_by_variable[idx] = []\n",
    "        coefficients_by_variable[idx].append(coeff)\n",
    "\n",
    "# Calcola media e statistica t per ogni variabile\n",
    "fama_macbeth_summary = {}\n",
    "num_periodi_validi = len(fama_macbeth_results)\n",
    "\n",
    "for idx, coeff_list in coefficients_by_variable.items():\n",
    "    mean_coefficient = np.mean(coeff_list)\n",
    "    \n",
    "    std_dev = np.std(coeff_list, ddof=1)\n",
    "    \n",
    "    t_statistic = mean_coefficient / (std_dev / np.sqrt(num_periodi_validi))\n",
    "    \n",
    "    fama_macbeth_summary[f'variabile_{idx}'] = {\n",
    "        'mean_coefficient': mean_coefficient,\n",
    "        't_statistic': t_statistic,\n",
    "        'std_dev': std_dev\n",
    "    }\n",
    "\n",
    "# Suddividi i periodi in gruppi da 8 e calcola media e t-statistica per ogni variabile\n",
    "fama_macbeth_summary_8 = {}\n",
    "num_groups = num_periodi // 8\n",
    "if num_periodi % 8 != 0:\n",
    "    num_groups += 1\n",
    "\n",
    "for group in range(num_groups):\n",
    "    start_period = group * 8\n",
    "    end_period = min((group + 1) * 8, num_periodi)\n",
    "\n",
    "    group_coefficients = {}\n",
    "    for idx, coeff_list in coefficients_by_variable.items():\n",
    "        group_coefficients[idx] = coeff_list[start_period:end_period]\n",
    "\n",
    "    for idx, coeff_list in group_coefficients.items():\n",
    "        mean_coefficient = np.mean(coeff_list)\n",
    "        std_dev = np.std(coeff_list, ddof=1)\n",
    "        t_statistic = mean_coefficient / (std_dev / np.sqrt(len(coeff_list)))\n",
    "\n",
    "        fama_macbeth_summary_8[f'group_{group+1}_variabile_{idx}'] = {\n",
    "            'mean_coefficient': mean_coefficient,\n",
    "            't_statistic': t_statistic,\n",
    "            'std_dev': std_dev\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d66d9e-cc7e-417f-8acc-c400df1d1685",
   "metadata": {},
   "source": [
    "## Visualizzazione coefficienti (Premi per il Rischio). \n",
    "Per ogni coefficiente si calcola la media annuale (dei 4 trimestri) e la signficativitÃ  di questo valore medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a979fd-bcac-477d-b7a3-db7b86752af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_coefficients_per_group = []\n",
    "t_statistics_per_group = []\n",
    "\n",
    "num_groups = num_periodi // 4 # un istogramma per ogni anno (4 trimestri)\n",
    "\n",
    "for group in range(num_groups):\n",
    "    start_idx = group * 4\n",
    "    end_idx = start_idx + 4\n",
    "\n",
    "    group_coefficients = []\n",
    "    group_t_statistics = []\n",
    "\n",
    "    # Calcolo la media e la t-statistic per ciascuna variabile in questo gruppo\n",
    "    for idx in coefficients_by_variable:\n",
    "        coefficients_for_group = coefficients_by_variable[idx][start_idx:end_idx]\n",
    "        \n",
    "        mean_coefficient = np.mean(coefficients_for_group)\n",
    "        std_dev = np.std(coefficients_for_group, ddof=1)\n",
    "        \n",
    "        t_statistic = mean_coefficient / (std_dev / np.sqrt(4)) # 4 Ã¨ il nuemro di trimestri nel gruppo \n",
    "\n",
    "        group_coefficients.append(mean_coefficient)\n",
    "        group_t_statistics.append(t_statistic)\n",
    "\n",
    "    mean_coefficients_per_group.append(group_coefficients)\n",
    "    t_statistics_per_group.append(group_t_statistics)\n",
    "\n",
    "# Visualizzazione dei dati in due istrogrammi, uno per la media e uno per la statistica tmean_coefficients_per_group = np.array(mean_coefficients_per_group)\n",
    "t_statistics_per_group = np.array(t_statistics_per_group)\n",
    "\n",
    "group_labels = [f'{2003 + (i*1)}' for i in range(num_groups)] \n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "bar_width = 0.2  \n",
    "opacity = 0.8  \n",
    "\n",
    "# Istogramma per le medie dei coefficienti\n",
    "for i in range(mean_coefficients_per_group.shape[1]):\n",
    "    ax[0].bar(np.array(range(num_groups)) + (i - 1) * bar_width, mean_coefficients_per_group[:, i],\n",
    "              width=bar_width, alpha=opacity, label=f'Variabile {i+1}', edgecolor='black')\n",
    "\n",
    "ax[0].set_title('Media dei Coefficienti per Ogni Gruppo di Periodi', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('Intervallo Temporale', fontsize=12)\n",
    "ax[0].set_ylabel('Media del Coefficiente', fontsize=12)\n",
    "ax[0].set_xticks(np.arange(num_groups))\n",
    "ax[0].set_xticklabels(group_labels, rotation=45, ha=\"right\", fontsize=10)\n",
    "ax[0].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "ax[0].legend(title='Variabili', loc='upper left', fontsize=10)\n",
    "\n",
    "# Istogramma per le t-statistics\n",
    "for i in range(t_statistics_per_group.shape[1]):\n",
    "    ax[1].bar(np.array(range(num_groups)) + (i - 1) * bar_width, t_statistics_per_group[:, i],\n",
    "              width=bar_width, alpha=opacity, label=f'Variabile {i+1}', edgecolor='black')\n",
    "\n",
    "ax[1].set_title('t-statistic per Ogni Gruppo di Periodi', fontsize=14, fontweight='bold')\n",
    "ax[1].set_xlabel('Intervallo Temporale', fontsize=12)\n",
    "ax[1].set_ylabel('t-statistic', fontsize=12)\n",
    "ax[1].set_xticks(np.arange(num_groups))\n",
    "ax[1].set_xticklabels(group_labels, rotation=45, ha=\"right\", fontsize=10)\n",
    "ax[1].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "ax[1].legend(title='Variabili', loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Calcolo e print del numero di gruppi significativi per ogni fattore\n",
    "t_stat_significance_threshold = 1.96  # Soglia per il 95% di confidenza\n",
    "\n",
    "significant_variables = {1: 0, 2: 0, 3: 0, 4: 0}  \n",
    "\n",
    "\n",
    "for group_idx in range(num_groups):\n",
    "    for var_idx in range(mean_coefficients_per_group.shape[1]):\n",
    "        t_stat = t_statistics_per_group[group_idx, var_idx]\n",
    "        \n",
    "        \n",
    "        if abs(t_stat) > t_stat_significance_threshold:\n",
    "            significant_variables[var_idx + 1] += 1 \n",
    "\n",
    "# Stampa il numero di gruppi significativi per ciascuna variabile\n",
    "print(\"Variabili significative per ogni variabile:\")\n",
    "for variable, count in significant_variables.items():\n",
    "    print(f\"Variabile {variable}: {count} gruppi significativi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
